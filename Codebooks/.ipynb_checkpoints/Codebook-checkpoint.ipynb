{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serverless Neural Network Codebook: 2-Layer Sample\n",
    "## Libraries, Global and Event Variables\n",
    "### Libraries\n",
    "The packages that will be needed by the Lambda Functions are declared in the `Utils` Python file, namely: \n",
    "- [datetime](https://docs.python.org/2/library/datetime.html) provides classes for manipulating dates and times in both simple and complex ways.\n",
    "- [numpy](www.numpy.org) is the fundamental package for scientific computing with Python.\n",
    "- [h5py](http://www.h5py.org) is a common package to interact with a dataset that is stored on an H5 file.\n",
    "- [matplotlib](http://matplotlib.org) is a famous library to plot graphs in Python.\n",
    "- [PIL](http://www.pythonware.com/products/pil/) and [scipy](https://www.scipy.org/) are used here to test your model with your own picture at the end.\n",
    "- [boto3](https://pypi.python.org/pypi/boto3) is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python, which allows Python developers to write software that makes use of services like Amazon S3 and Amazon EC2.\n",
    "- [json](https://docs.python.org/3/library/json.html) is a lightweight data interchange format inspired by JavaScript object literal syntax (although it is not a strict subset of JavaScript.\n",
    "- [os](https://docs.python.org/3/library/os.html) is a module the provides a portable way of using operating system dependent functionality. Particularly the  `environ` object is a mapping object representing the environment.\n",
    "- [uuid](https://docs.python.org/2/library/uuid.html#uuid.uuid4) creates a unique, random ID.\n",
    "- The [io](https://docs.python.org/2/library/io.html) module provides the Python interfaces to stream handling.\n",
    "- The Python interface to the [Redis](https://pypi.python.org/pypi/redis) key-value store.\n",
    "- [math](https://docs.python.org/3/library/math.html) to determine the last mini-batch size when partitioning the Training Data Set into mini-batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries needed by the Lambda Function\n",
    "from Utils import *\n",
    "\n",
    "# Import libraries needed for the Codebook\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (11.0, 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3 Trigger Event\n",
    "To initiate the network training process, the dataset (**datasets.h5**) is uploaded to Amazon Simple Storage Services ([S3](https://aws.amazon.com/s3/)). This porcess triggers the S3 bucket event wich starts the training process. A sample of the event payload sent to the SNN framework is as follows:\n",
    "\n",
    ">**Note:** In order for the *2-Layer Sample* to work, please update the following lines in the code below and add the name of the S3 Bucket created during deployment. For example:\n",
    "```json\n",
    "    \"bucket\": {\n",
    "        \"arn\": \"arn:aws:s3:::<BUCKET Name>\",\n",
    "        \"name\": \"<Bucket Name>\",\n",
    "    ...\n",
    "```\n",
    "For this version of the implementation, the S3 Bucket is called **itsacat-demo** and the folder is called **training_input**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simulate S3 event trigger data\n",
    "event = {\n",
    "    \"Records\": [\n",
    "        {\n",
    "            \"eventVersion\": \"2.0\",\n",
    "            \"eventTime\": \"1970-01-01T00:00:00.000Z\",\n",
    "            \"requestParameters\": {\n",
    "                \"sourceIPAddress\": \"127.0.0.1\"\n",
    "             },\n",
    "            \"s3\": {\n",
    "                \"configurationId\": \"testConfigRule\",\n",
    "                \"object\": {\n",
    "                    \"eTag\": \"0123456789abcdef0123456789abcdef\",\n",
    "                    \"sequencer\": \"0A1B2C3D4E5F678901\",\n",
    "                    \"key\": \"training_input/datasets.h5\",\n",
    "                    \"size\": 1024\n",
    "                },\n",
    "                \"bucket\": {\n",
    "                    \"arn\": \"arn:aws:s3:::inn-tmp\",\n",
    "                    \"name\": \"lnn-tmp\",\n",
    "                    \"ownerIdentity\": {\n",
    "                        \"principalId\": \"EXAMPLE\"\n",
    "                    }\n",
    "                },\n",
    "                \"s3SchemaVersion\": \"1.0\"\n",
    "            },\n",
    "            \"responseElements\": {\n",
    "                \"x-amz-id-2\": \"EXAMPLE123/5678abcdefghijklambdaisawesome/mnopqrstuvwxyzABCDEFGH\",\n",
    "                \"x-amz-request-id\": \"EXAMPLE123456789\"\n",
    "            },\n",
    "            \"awsRegion\": \"us-west-2\",\n",
    "            \"eventName\": \"ObjectCreated:Put\",\n",
    "            \"userIdentity\": {\n",
    "                \"principalId\": \"EXAMPLE\"\n",
    "            },\n",
    "            \"eventSource\": \"aws:s3\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "context = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To establish client connectivity to the various AWS services that the function will leverage, the following code creates the needed clients for the various AWS services, as global variables.\n",
    "\n",
    "### Global Variables\n",
    ">**Note:** The AWS Region is declared at the time of deployment. The `rgn` variable is declared from the above event in order to simulate its funcitonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simulate Region variable\n",
    "rgn = event['Records'][0]['awsRegion']\n",
    "\n",
    "# Global Variables\n",
    "s3_client = client('s3', region_name=rgn) # S3 low level class object\n",
    "s3_resource = resource('s3') # S3 high level service class\n",
    "lambda_client = client('lambda', region_name=rgn) # Lambda invocation client\n",
    "redis_client = client('elasticache', region_name=rgn) # ElastiCache low level object\n",
    "\n",
    "# Find and retrieve the Elasticache Cluster endpoint\n",
    "cc = redis_client.describe_cache_clusters(ShowCacheNodeInfo=True)\n",
    "endpoint = cc['CacheClusters'][0]['CacheNodes'][0]['Endpoint']['Address']\n",
    "cache = redis(host=endpoint, port=6379, db=15) # Connect Python to Redis Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Overview\n",
    "### Training and Test Datasets\n",
    "It is **very important** in Neural Network programming (without the use of a Deep Learning Framework), to have a full understanding of the dimensions of the input data as well as how the dimensions are transformed at each layer, therefore to build a simple image-recognition algorithm that can correctly classify pictures as cat or non-cat, the following cells explain the datsets.\n",
    "\n",
    "To train the Neural Network, we are provided with a dataset (`datasets.h5`) containing:\n",
    "- a training set of $m$ images containing cats and non-cats as well as the appropriate class labels ($y=1$) and non-cat images ($y=0$).\n",
    "- a test set of $m$ images containing cats and non-cat sas well as the appropriate class labels ($y=1$) and non-cat images ($y=0$).\n",
    "- classes list for cat and non-cat images.\n",
    "\n",
    ">**Note:** The original dataset was comprised of two separate files, `test_catvnoncat.h5` and `train_catvnoncat.h5`. For the sake of this implementation a single file is needed to upload to the *S3 Bucket*, `datasets.h5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_classes\n",
      "test_set_x\n",
      "test_set_y\n",
      "train_set_x\n",
      "train_set_y\n"
     ]
    }
   ],
   "source": [
    "# Load main dataset that's stored locally\n",
    "dataset = h5py.File('datasets/datasets.h5', \"r\")\n",
    "\n",
    "# Get the names of the unique datsets\n",
    "datasetNames = [n for n in dataset.keys()]\n",
    "for n in datasetNames:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create numpy arrays of the various unique datasets\n",
    "train_set_x_orig = np.array(dataset[\"train_set_x\"][:]) # train set features\n",
    "train_set_y_orig = np.array(dataset[\"train_set_y\"][:]) # train set labels\n",
    "test_set_x_orig = np.array(dataset[\"test_set_x\"][:]) # test set features\n",
    "test_set_y_orig = np.array(dataset[\"test_set_y\"][:]) # test set labels\n",
    "classes = np.array(dataset[\"list_classes\"][:]) # the list of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x_orig dimensions: (209, 64, 64, 3)\n",
      "train_set_y_orig dimension: (209,)\n",
      "test_set_x_orig dimensions: (50, 64, 64, 3)\n",
      "test_set_y_orig dimensions: (50,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaye the dimensions of each unique data set\n",
    "print(\"train_set_x_orig dimensions: \" + str(train_set_x_orig.shape))\n",
    "print(\"train_set_y_orig dimension: \" + str(train_set_y_orig.shape))\n",
    "print(\"test_set_x_orig dimensions: \" + str(test_set_x_orig.shape))\n",
    "print(\"test_set_y_orig dimensions: \" + str(test_set_y_orig.shape))\n",
    "test_set_y_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the cell above, the image data (`train_set_x_orig` and `test_set_x_orig`) are 4-dimensional arrays consiting of $209$ training examoples (**m_train**) and $50$ testing images (**m_test**) respectively. Each image is in turn of *height*, *width* and *depth* (**R**ed, **G**reen **B**lue values) of $64 \\times 64 \\times 3$.\n",
    "\n",
    "Additionally, the dimension for the labels (`train_set_y_orig` and `test_set_y_orig`) only show a $209$ and $50$ column structure. So it is recommended when coding new networks, don't use data structures where the shape is $5$, or $n$, rank 1 array. Instead, this is set to, `(1, 209)` and `(1, 50)`, to make them a **row vector**, and in essence add another dimension to the `Numpy` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create row vectors for the labels.\n",
    "train_set_y = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "test_set_y = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_y dimensions: (1, 209)\n",
      "test_set_y dimensions: (1, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"train_set_y dimensions: \" + str(train_set_y.shape))\n",
    "print(\"test_set_y dimensions: \" + str(test_set_y.shape))\n",
    "test_set_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Now that the additional dimension has been added to the label data, we can note the additional \"[[ ]]\" when displaying the array.\n",
    "\n",
    "Next we can see the label data and view the corresponding image, in this case, $index = 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = [1], and therefore it's a 'cat' picture.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkUAAAJCCAYAAADOe7N5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSQLg/wCYhIM+QYr3ZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e0a86c4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a cat picture\n",
    "index = 2\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "print (\"y = \" + str(train_set_y[:, index]) + \\\n",
    "       \", and therefore it's a '\" + \\\n",
    "       classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") + \\\n",
    "       \"' picture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.squeeze()` method extracts the \" inner dimension\" of the array, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_y[:, index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(train_set_y[:, index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** The \"[ ]\" has been removed.\n",
    "\n",
    "### Data Preprocessing\n",
    "The final model analysis (see **Analysis** Notebook)is expecting a *training* set and a *test* set represented by a numpy array of shape (no. pixels $\\times$ no. pixels $\\times$ depth, data set size) respectively. In turn, the model is expecting the training set and test set labels represented as a numpy array (vector) of shape (1, data set size) respectively.\n",
    "\n",
    ">**Note:** It is not determined as yet wether the \"vectorization\" of the images should be performed by the `TrainerLambda` to set up the inputs for *Layer 0*. For the sake of Version 1.0, the preprocessing of the input data will be performed by `launch.py` as various helper functions.\n",
    "\n",
    "#### Vectorize\n",
    "The images are represented by a 3D array of shape $(length, height, depth = 3)$. However, when an image is read as the input of an algorithm it is converted to a vector of shape $(length*height*3, 1)$. In other words, it is \"unrolled\", \"flattened\" or \"reshaped\" from a 3D array into a 1D vector as can be seen below.\n",
    "\n",
    "<img src=\"images/vectorization.png\" style=\"width:800px;height:500px;\">\n",
    "<caption><left>[*image source](https://www.deeplearning.ai)</left></caption><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following cells explains of this process using the `train_set_x_orig` numpy array. The end result for the input to the model is a is a numpy array where where each column represents a flattened image in a matrix with all the input features (images) being a column, $209$ for the training set and $50$ for the test set respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (209, 64, 64, 3)\n",
      "Flattened shape: (209, 12288)\n",
      "Transpose: (12288, 209)\n"
     ]
    }
   ],
   "source": [
    "# Copy of origional training set\n",
    "orig = train_set_x_orig\n",
    "print(\"Original shape: \" + str(orig.shape))\n",
    "\n",
    "# \"vectorize\" or flatten out the array into an 1D vector\n",
    "flatten = orig.reshape(orig.shape[0], -1)\n",
    "print(\"Flattened shape: \"+ str(flatten.shape))\n",
    "\n",
    "# Transpose into a colums\n",
    "flatten_T = flatten.T\n",
    "print(\"Transpose: \" + str(flatten_T.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** For further intuition of what the above code is doing, the following shows a more \"manual\", alternate way.\n",
    "\n",
    "#### Standardize\n",
    "To represent color images, the red, green and blue channels (RGB) must be specified for each pixel, and so the pixel value is actually a vector of three numbers ranging from $0$ to $255$. One common preprocessing step in machine learning is to subtract the mean of the whole numpy array from each example, and then divide each example by the standard deviation of the whole numpy array. But for picture datasets, it is simpler and more convenient and works almost as well to just divide every row of the dataset by $255$ (the maximum value of a pixel channel). \n",
    "\n",
    ">**Note:** During the training of the model, the weights are multiplied and biases added to the initial inputs in order to observe neuron activations. Then it will backward propagate with the gradients to train the model. But, it is extremely important for each feature to have a similar range such that our gradients don't explode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x shape: (12288, 209)\n",
      "sample value: 0.266666666667\n"
     ]
    }
   ],
   "source": [
    "# Load datsets for preprocessing after vectorization\n",
    "train_set_x = (train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T) / 255\n",
    "test_set_x = (test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T) / 255\n",
    "print(\"train_set_x shape: \" + str(train_set_x.shape))\n",
    "print(\"sample value: \" + str(train_set_x[index][index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Function Overview\n",
    "### Helper Functions\n",
    "All Helper funcitons are defined within the `Utils` Python file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda Handler Functions\n",
    "#### `launch_handler(event, context)`\n",
    "This `lambda_handler()` is triggered by the S3 event where training data is uploaded to S3. It further initializes the various components needed, such as:\n",
    "1. State tracking Objects:\n",
    "    - Overall Results (Cost) for each Epoch.\n",
    "    - Gradients for each layer.\n",
    "    - Initial and updated Weight parameter for each layer.\n",
    "    - Initial and updated Bias parameter for each layer.\n",
    "2. DynamoDB Storage:\n",
    "    - Invocation ID for each Lambda Function invocation to prevent duplicate invocation.\n",
    "    >**Note:** The DynamoDB Initialization is **NOT** recorded within the **Codebook**.\n",
    "3. Preprocessing the Input Data: \n",
    "    - Read in the the initial *training*, *test* of Cat and Non-cat images.\n",
    "    - The function initially loads the data in `h5py` format and extracts the *training* and *test* data.\n",
    "    - The function further performs any standardization and normalization of the input data.\n",
    "    - The function also \"*flattens*\" the data into a column vector, thus performing **Vectorization**.\n",
    "    - This data is dumped to ElastiCache and will thus serve as **Layer 0** of the Neural Network.\n",
    "4. Initialize the mini-batches\n",
    "    - Initial shuffel and mini-batch partitioning of the pre-processed training data.\n",
    "5. Master Environment and State Tracking Variables:\n",
    "    - Loading the initial Neural Network Parameters (`parameters.json`) and augmenting these parameter with the state variables during the training process. The settings include overall parameters used by the `trainer` and `neuron` Lambda Functions, such as:\n",
    "        - Total number of epochs/iterations.\n",
    "        - Total number of batches.\n",
    "        - Total number of layers in the Neural Network (including the Output layer).\n",
    "        - Total number of \"neurons\" in each layer.\n",
    "        - The activation function to be used for each layer.  \n",
    "    - Initializing the **Hash Keys** for the various data sets in ElastiCache to be used by the subsequent functions to get access to the numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def launch_handler(event, context):\n",
    "    # Determine if this is the initial launch of the funciton\n",
    "    if not event.get('state') == 'next':\n",
    "        # This is the first invocation, therefore set up the initial parameters\n",
    "        # Retrieve datasets and parmeters from S3\n",
    "        input_bucket = s3_resource.Bucket(str(event['Records'][0]['s3']['bucket']['name']))\n",
    "        dataset_key = str(event['Records'][0]['s3']['object']['key'])\n",
    "        settings_key = dataset_key.split('/')[-2] + '/parameters.json'\n",
    "        try:\n",
    "            input_bucket.download_file(dataset_key, '/tmp/datasets.h5')\n",
    "            input_bucket.download_file(settings_key, '/tmp/parameters.json')\n",
    "        except botocore.exceptions.ClientError as e:\n",
    "            if e.response['Error']['Code'] == '404':\n",
    "                sns_message = \"Error downloading input data from S3, S3 object does not exist\"\n",
    "                #publish_sns(sns_message)\n",
    "                print(sns_message)\n",
    "            else:\n",
    "                raise\n",
    "        \n",
    "        # Extract the neural network paramaters\n",
    "        with open('/tmp/parameters.json') as parameters_file:\n",
    "            parameters = json.load(parameters_file)\n",
    "        \n",
    "        # Start building the Master parameters\n",
    "        # Get the ARNs for the Lambda Functions\n",
    "        parameters['ARNs'] = {\n",
    "            'LaunchLambda': get_arns('LaunchLambda'),\n",
    "            'TrainerLambda': get_arns('TrainerLambda'),\n",
    "            'NeuronLambda': get_arns('NeuronLambda')\n",
    "        }\n",
    "        # Input data set and parameter bucket\n",
    "        parameters['s3_bucket'] = event['Records'][0]['s3']['bucket']['name']\n",
    "        # Initial epoch for tracking\n",
    "        parameters['epoch'] = 0\n",
    "        \n",
    "        # Initialize and pre-process the training set\n",
    "        X, Y = initialize_data(parameters)\n",
    "        \n",
    "        # Upload the pre-processed data sets to the Master ElastiCache DB (db=15)\n",
    "        # and update the parameters with the keys\n",
    "        parameters['data_keys'] = {}\n",
    "        parameters['data_keys']['X'] = to_cache(db=15, obj=X, name='X')\n",
    "        parameters['data_keys']['Y'] = to_cache(db=15, obj=Y, name='Y')\n",
    "        \n",
    "        # Initialize the Weights and Bias using Xavier Initialization\n",
    "        # for the ReLU neurons\n",
    "        for l in range(1, parameters['layers']+1):\n",
    "            if l == 1:\n",
    "                \"\"\"\n",
    "                Note: This assumes Layer 1 uses the ReLU Activation.\n",
    "                \"\"\"\n",
    "                # Standard Wieght initialization for ReLU\n",
    "                W = np.random.randn(\n",
    "                    parameters['neurons']['layer'+str(l)],\n",
    "                    X.shape[0]\n",
    "                ) * np.sqrt((2.0 / X.shape[0]))\n",
    "            else:\n",
    "                if parameters['activations']['layer'+str(l)] == 'sigmoid':\n",
    "                    # Standard Weight initialization\n",
    "                    W = np.random.randn(\n",
    "                        parameters['neurons']['layer'+str(l)],\n",
    "                        parameters['neurons']['layer'+str(l-1)]\n",
    "                    ) / np.sqrt(parameters['neurons']['layer'+str(l-1)])\n",
    "                else:\n",
    "                    # Xavier Weight initialization for ReLu\n",
    "                    W = np.random.randn(\n",
    "                        parameters['neurons']['layer'+str(l)],\n",
    "                        parameters['neurons']['layer'+str(l-1)]\n",
    "                    ) * np.sqrt((2.0 / parameters['neurons']['layer'+str(l-1)]))\n",
    "            # Standard Bias initialization\n",
    "            b = np.zeros((parameters['neurons']['layer'+str(l)], 1))\n",
    "            # Upload the Weights and Bias to ElastiCache Master DB\n",
    "            parameters['data_keys']['W'+str(l)] = to_cache(db=15, obj=W, name='W'+str(l))\n",
    "            parameters['data_keys']['b'+str(l)] = to_cache(db=15, obj=b, name='b'+str(l))\n",
    "        \n",
    "        # Initialize mini-batches\n",
    "        batch_size = parameters['batch_size']\n",
    "        batches = random_minibatches(X, Y, batch_size)\n",
    "        parameters['num_batches'] = len(batches)\n",
    "        \n",
    "        # Update Master parameters to ElastiCache\n",
    "        parameter_key = to_cache(db=15, obj=parameters, name='paremeters')\n",
    "        \n",
    "        # Initialize DynamoDB tables for treacking Lambda invocations \n",
    "        \"\"\"\n",
    "        Note: This is not necessary for the 2-Layer Sample.\n",
    "        \n",
    "        table_list = ['LaunchLambda','TrainerLambda', 'NeuronLambda']\n",
    "        for t in table_list:\n",
    "            # Check to see if the table already exists\n",
    "            list_response = dynamo_client.list_tables()\n",
    "            if t in list_response['TableNames']:\n",
    "                # Delete the existing table\n",
    "                dynamo_client.delete_table(TableName=t)\n",
    "                waiter = dynamo_client.get_waiter('table_not_exists')\n",
    "                waiter.wait(TableName=t)\n",
    "            \n",
    "            # Create a \"fresh\" table\n",
    "            table = dynamo_resource.create_table(\n",
    "                TableName=t,\n",
    "                KeySchema=[\n",
    "                    {\n",
    "                        'AttributeName': 'invID',\n",
    "                        'KeyType': 'HASH'\n",
    "                    },\n",
    "                ],\n",
    "                AttributeDefinitions=[\n",
    "                    {\n",
    "                        'AttributeName': 'invID',\n",
    "                        'AttributeType': 'S'\n",
    "                    },\n",
    "                ],\n",
    "                ProvisionedThroughput={\n",
    "                    'ReadCapacityUnits': 20,\n",
    "                    'WriteCapacityUnits': 50\n",
    "                }\n",
    "            )\n",
    "            table.meta.client.get_waiter('table_exists').wait(TableName=t)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Invoke the training for each batch by invoking the `TrainerLambda`\n",
    "        current_batch = -1\n",
    "        for batch in batches:\n",
    "            # Create parameters that are specific to the batch, `batch_parameters`\n",
    "            current_batch += 1\n",
    "            (batch_X, batch_Y) = batch\n",
    "            m = batch_X.shape[1]\n",
    "            batch_parameters = parameters\n",
    "            batch_parameters['batch_ID'] = current_batch\n",
    "            batch_parameters['data_keys']['A0'] = to_cache(\n",
    "                db=current_batch,\n",
    "                obj=batch_X,\n",
    "                name='A0'\n",
    "            )\n",
    "            batch_parameters['data_keys']['Y'] = to_cache(\n",
    "                db=current_batch,\n",
    "                obj=batch_Y,\n",
    "                name='Y'\n",
    "            )\n",
    "            batch_parameters['data_keys']['m'] = to_cache(\n",
    "                db=current_batch,\n",
    "                obj=m,\n",
    "                name='m'\n",
    "            )\n",
    "            \n",
    "            # Debug Statements\n",
    "            #print(\"\\n\"+\"\\n\"+\"Batch {} Parameters: \".format(current_batch))\n",
    "            #print(dumps(batch_parameters, indent=4, sort_keys=True))\n",
    "            \n",
    "            # Initialize the payload for current batch to `TrainerLambda`\n",
    "            payload = {}\n",
    "            payload['state'] = 'start' # Initialize overall state\n",
    "            payload['batch_ID'] = current_batch # Append the batch ID\n",
    "            payload['parameter_key'] = to_cache(\n",
    "                db=current_batch,\n",
    "                obj=batch_parameters,\n",
    "                name='parameters'\n",
    "            )\n",
    "            \n",
    "            # Create the invocation ID to ensure no duplicate functions\n",
    "            # are launched\n",
    "            \"\"\"\n",
    "            Note: This is not necessary for the 2-Layer sample\n",
    "            \n",
    "            invID = str(uuid.uuid4()).split('-')[0]\n",
    "            name = 'TrainerLambda'\n",
    "            task = 'set'\n",
    "            inv_counter(name, invID, task)\n",
    "            payload['invID'] = invID\n",
    "            \n",
    "            # Prepare the payload for `TrainerLambda`\n",
    "            payloadbytes = dumps(payload)\n",
    "            \n",
    "            # Debug Statements\n",
    "            #print(\"Complete Neural Network Settings for batch: {}\\n\".format(current_batch))\n",
    "            #print(dumps(batch_parameters, indent=4, sort_keys=True))\n",
    "            #print(\"\\n\"+\"Payload to be sent to TrainerLambda: \\n\")\n",
    "            #print(dumps(payload))\n",
    "            \n",
    "            # Invoke TrainerLambda to start the training process for\n",
    "            # the current batch\n",
    "            try:\n",
    "                response = lambda_client.invoke(\n",
    "                    FunctionName=batch_parameters['ARNs']['TrainerLambda'],\n",
    "                    InvocationType='Event',\n",
    "                    Payload=payloadbytes\n",
    "                )\n",
    "            except botocore.exceptions.ClientError as e:\n",
    "                sns_message = \"Errors occurred invoking TrainerLambda from LaunchLambda.\"\n",
    "                sns_message += \"\\nError:\\n\" + str(e)\n",
    "                sns_message += \"\\nCurrent Payload:\\n\" +  dumps(payload, indent=4, sort_keys=True)\n",
    "                publish_sns(sns_message)\n",
    "                print(e)\n",
    "                raise\n",
    "            print(response)\n",
    "            \"\"\"\n",
    "            \n",
    "            # Launch `trainer_handler` for 2-Layer Sample\n",
    "            trainer_handler(event=payload, context=None)\n",
    "            \n",
    "    \"\"\"\n",
    "    To Do: Completenext stage if this is not the first time the function is called\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `trainer_handler(event, context)`\n",
    "This `lambda_handler()` function is the most critical function in the set in that it:\n",
    "1. Tracks and updates the state across the Mini-batches and the various layers of the Neural Network.\n",
    "2. Performs Vectorization on the Activation Row Vectors from each Neuron to create a *Matrix* of Activations.\n",
    "3. Launches the various Neurons (`NeuronLambda`) in each layer and tracks their output for *Forward* or *Backward* propogation.\n",
    "4. Calculates the *Cost* for each iteration of *Forward* propagation.\n",
    "5. Performs *Gradient Descent* for the current Mini-Batch.\n",
    "6. Calls the `LaunchLambda` to start the next Epoch.\n",
    "\n",
    "In order to accomplish this, the `TrainerLambda` has three possible states, `start`, `forward` and `backward`:\n",
    "1. `start`: This state starts the initial or subsequent training epochs and performs the following:\n",
    "    - Initializes the new weights and bias for the epoch.\n",
    "    - Updates the state table with these values.\n",
    "2. `forward`: This state processes the *forward* propagation step and launches the various hidden layer Neurons and supplies the necessary state information to these functions, such as:\n",
    "    - Input/Activation data location\n",
    "    - Weights and Bias.\n",
    "    - Hidden Layer No.\n",
    "    - Number of Hidden Units.\n",
    "    - Activation Funciton for the Layer.\n",
    "3. `backward`: This state processes the *back* propagation step and launches the various hidden layer Neurons as well as supplies the necessary information for these functions, like:\n",
    "    - Hidden Layer No.\n",
    "    - Number of Hidden Units.\n",
    "    - Current and previous Activations calculated from the forward propagation step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Origional Function\n",
    "```Python\n",
    "def trainer_handler(event, context):\n",
    "    \"\"\"\n",
    "    1. Processes the `event` variables from the various Lambda functions that call it, \n",
    "        i.e. `TrainerLambda` and `NeuronLambda`.\n",
    "    2. Determines the \"current\" state and then directs the next steps.\n",
    "    3. Performs Vectorization from the NeuronLambda forward propagation outputs.\n",
    "    4. Calculates the Cost.\n",
    "    5. Performs Gradient Descent given the gradients from the backward propagation outputs.\n",
    "    \"\"\"\n",
    "    # Get the current state from the invoking lambda\n",
    "    state = event.get('state')\n",
    "    global parameters\n",
    "    parameters = from_cache(endpoint=endpoint, key=event.get('parameter_key'))\n",
    "    \n",
    "    # Execute appropriate action based on the the current state\n",
    "    if state == 'forward':\n",
    "        # Perform vectorization to create a matrix of activations and/or calculate the Cost\n",
    "        # Get important state variables\n",
    "        epoch = event.get('epoch')\n",
    "        layer = event.get('layer')\n",
    "\n",
    "        # Get the Vectorized matrix of Activations\n",
    "        A = vectorizer(Outputs='a', Layer=layer-1)\n",
    "\n",
    "        # Add the `A` Matrix to `data_keys` for later Neuron use\n",
    "        A_name = 'A' + str(layer-1)\n",
    "        parameters['data_keys'][A_name] = to_cache(endpoint=endpoint, obj=A, name=A_name)\n",
    "\n",
    "        # Update ElastiCache with this function's data\n",
    "        parameter_key = to_cache(endpoint=endpoint, obj=parameters, name='parameters')\n",
    "        \n",
    "        # Determine the location within forwardprop\n",
    "        if layer > parameters['layers']:\n",
    "            # Location is at the end of forwardprop, therefore calculate Cost\n",
    "            # Get the training examples data and no. examples (`Y` and `m`)\n",
    "            Y = from_cache(endpoint=endpoint, key=parameters['data_keys']['Y'])\n",
    "            m = from_cache(endpoint=endpoint, key=parameters['data_keys']['m'])\n",
    "            \n",
    "            # Calculate the Cross-Entropy Cost\n",
    "            l2 = parameters['lambda']\n",
    "            cross_entropy_cost = (1./m) * (-np.dot(Y, np.log(A).T) - np.dot(1 - Y, np.log(1 - A).T))\n",
    "            \n",
    "            # Calculate L2 Cost\n",
    "            l2_cost = 0\n",
    "            for l in range(1, parameters['layers']+1):\n",
    "                W = from_cache(endpoint=endpoint, key=parameters['data_keys']['W'+str(l)])\n",
    "                l2_cost += np.sum(np.square(W))\n",
    "            \n",
    "            # Final Cost with L2 Regularization\n",
    "            cost = cross_entropy_cost + (l2 / (2 * m)) * l2_cost\n",
    "            cost = np.squeeze(cost)\n",
    "            assert(cost.shape == ())\n",
    "\n",
    "            # Update results with the Cost\n",
    "            # Get the results object\n",
    "            cost2results = from_cache(endpoint=endpoint, key=parameters['data_keys']['results'])\n",
    "            # Append the cost to results object\n",
    "            cost2results['epoch' + str(epoch)]['cost'] = float(cost)\n",
    "            # Update results key in ElastiCache\n",
    "            parameters['data_keys']['results'] = to_cache(endpoint=endpoint, obj=cost2results, name='results')\n",
    "\n",
    "            print(\"Cost after epoch {}: {}\".format(epoch, cost))\n",
    "\n",
    "            # Initialize backprop\n",
    "            # Calculate the derivative of the Cost with respect to the last activation\n",
    "            # Ensure that `Y` is the correct shape as the last activation\n",
    "            Y = Y.reshape(A.shape)\n",
    "            dA = - (np.divide(Y, A) - np.divide(1 - Y, 1 - A))\n",
    "            dA_name = 'dA' + str(layer-1)\n",
    "            parameters['data_keys'][dA_name] = to_cache(endpoint=endpoint, obj=dA, name=dA_name)\n",
    "\n",
    "            # Update parameters from this function in ElastiCache\n",
    "            parameter_key = to_cache(endpoint=endpoint, obj=parameters, name='parameters')\n",
    "\n",
    "            # Start Backpropagation on NeuronLambda\n",
    "            propogate(direction='backward', epoch=epoch, layer=layer-1, parameter_key=parameter_key)\n",
    "\n",
    "        else:\n",
    "            # Move to the next hidden layer for multiple layer networks\n",
    "            #debug\n",
    "            #print(\"Propagating forward onto Layer \" + str(layer))\n",
    "            propogate(direction='forward', epoch=epoch, layer=layer, parameter_key=parameter_key)\n",
    "        \n",
    "    elif state == 'backward':\n",
    "        # Get important state variables\n",
    "        epoch = event.get('epoch')\n",
    "        layer = event.get('layer')\n",
    "\n",
    "        # Vectorize the derivatives\n",
    "        dZ = vectorizer(Outputs='dZ', Layer=layer+1)\n",
    "        \n",
    "        # Next pre-process the derivative of the weights\n",
    "        dW = vectorizer(Outputs='dw', Layer=layer+1)\n",
    "        \n",
    "        # pre-process the derivatives of the bias\n",
    "        db = vectorizer(Outputs='db', Layer=layer+1)\n",
    "        db = db.reshape(db.shape[0], 1)\n",
    "        \n",
    "        # Determine the location within backprop\n",
    "        if epoch == parameters['epochs']-1 and layer == 0:\n",
    "            # Location is at the end of the final epoch\n",
    "            # Get relavent parameters for bacprop\n",
    "            W = from_cache(endpoint=endpoint, key=parameters['data_keys']['W'+str(layer+1)])\n",
    "            b = from_cache(endpoint=endpoint, key=parameters['data_keys']['b'+str(layer+1)])\n",
    "            learning_rate = parameters['learning_rate']\n",
    "            # Run Gradient Descent\n",
    "            W = W - learning_rate * dW\n",
    "            b = b - learning_rate * db\n",
    "\n",
    "            # Update ElastiCache with the new Weights and new Bias to be used as the inputs for\n",
    "            # the next epoch\n",
    "            parameters['data_keys']['W'+str(layer+1)] = to_cache(\n",
    "                endpoint=endpoint,\n",
    "                obj=W,\n",
    "                name='W'+str(layer+1)\n",
    "            )\n",
    "            parameters['data_keys']['b'+str(layer+1)] = to_cache(\n",
    "                endpoint=endpoint,\n",
    "                obj=b,\n",
    "                name='b'+str(layer+1)\n",
    "            )\n",
    "            \n",
    "            # Update parameters for the next epoch\n",
    "            parameter_key = to_cache(endpoint=endpoint, obj=parameters, name='parameters')\n",
    "                        \n",
    "            # Finalize the the process and clean up\n",
    "            end(parameter_key=parameter_key)\n",
    "            \n",
    "        elif epoch < parameters['epochs']-1 and layer == 0:\n",
    "            # Location is at the end of the current epoch and backprop is finished\n",
    "            # Get relevent parameters for backprop\n",
    "            W = from_cache(endpoint=endpoint, key=parameters['data_keys']['W'+str(layer+1)])\n",
    "            b = from_cache(endpoint=endpoint, key=parameters['data_keys']['b'+str(layer+1)])\n",
    "            learning_rate = parameters['learning_rate']\n",
    "            # Run Gradient Descent\n",
    "            W = W - learning_rate * dW\n",
    "            b = b - learning_rate * db\n",
    "\n",
    "            # Update ElastiCache with the new Weights and new Bias to be used as the inputs for\n",
    "            # the next epoch\n",
    "            parameters['data_keys']['W'+str(layer+1)] = to_cache(\n",
    "                endpoint=endpoint,\n",
    "                obj=W,\n",
    "                name='W'+str(layer+1)\n",
    "            )\n",
    "            parameters['data_keys']['b'+str(layer+1)] = to_cache(\n",
    "                endpoint=endpoint,\n",
    "                obj=b,\n",
    "                name='b'+str(layer+1)\n",
    "            )\n",
    "            \n",
    "            # Update parameters for the next epoch\n",
    "            parameter_key = to_cache(endpoint=endpoint, obj=parameters, name='parameters')\n",
    "                        \n",
    "            # Start the next epoch\n",
    "            start_epoch(epoch=epoch+1, layer=0, parameter_key=parameter_key)\n",
    "            \n",
    "        else:\n",
    "            \"\"\"\n",
    "            Location is still within the backprop process, therefore calculate \n",
    "            the derivative of the current layer's activations with respect to the \n",
    "            Cost as well as perform gradient decent to get and new weights and bias\n",
    "            \"\"\"\n",
    "            # Get relevent parameters for backprop\n",
    "            W = from_cache(endpoint=endpoint, key=parameters['data_keys']['W'+str(layer+1)])\n",
    "            b = from_cache(endpoint=endpoint, key=parameters['data_keys']['b'+str(layer+1)])\n",
    "            learning_rate = parameters['learning_rate']\n",
    "            dA = np.dot(W.T, dZ)\n",
    "            dA_name = 'dA' + str(layer)\n",
    "            parameters['data_keys'][dA_name] = to_cache(endpoint=endpoint, obj=dA, name=dA_name)\n",
    "\n",
    "            # Run Gradient Descent\n",
    "            W = W - learning_rate * dW\n",
    "            b = b - learning_rate * db\n",
    "            # Update ElastiCache with the new Weights and new Bias to be used as the\n",
    "            # inputs for the next epoch\n",
    "            parameters['data_keys']['W'+str(layer+1)] = to_cache(\n",
    "                endpoint=endpoint,\n",
    "                obj=W,\n",
    "                name='W'+str(layer+1)\n",
    "            )\n",
    "            parameters['data_keys']['b'+str(layer+1)] = to_cache(\n",
    "                endpoint=endpoint,\n",
    "                obj=b,\n",
    "                name='b'+str(layer+1)\n",
    "            )\n",
    "\n",
    "            # Update parameters from this function in ElastiCache\n",
    "            parameter_key = to_cache(endpoint=endpoint, obj=parameters, name='parameters')\n",
    "\n",
    "            # Move to the next hidden layer\n",
    "            propogate(direction='backward', epoch=epoch, layer=layer, parameter_key=parameter_key)\n",
    "            \n",
    "    elif state == 'start':\n",
    "        # Start training process        \n",
    "        # Create initial parameters\n",
    "        epoch = 0\n",
    "        layer = 0\n",
    "        start_epoch(epoch=epoch, layer=layer, parameter_key=event.get('parameter_key'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `neuron_handler(event, context)`\n",
    "This `lambda_handler()` simulates a single *Perceptron* for both forward and backward propagation. If the state is `forward` then the function simulates forward propagation for $X$ to $Cost$ for the current layer. If the state is backward, then the function calculates the gradient of the derivative of the activation function for the current layer.\n",
    "\n",
    ">**Note:** This function also moves the state to the next or previous layer, depending on the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron_handler(event, context):\n",
    "    \"\"\"\n",
    "    This Lambda Funciton simulates a single Perceptron for both \n",
    "    forward and backward propogation.\n",
    "    \"\"\"    \n",
    "    # Get the Neural Network parameters from Elasticache\n",
    "    parameters = from_cache(endpoint, key=event.get('parameter_key'))\n",
    "       \n",
    "    # Get the current state\n",
    "    state = event.get('state')\n",
    "    epoch = event.get('epoch')\n",
    "    layer = event.get('layer')\n",
    "    ID = event.get('id') # To be used when multiple activations\n",
    "    # Determine is this is the last Neuron in the layer\n",
    "    last = event.get('last')\n",
    "    activation = event.get('activation')\n",
    "    # Debug Statement\n",
    "    #print(\"Starting {} propagation on Neuron: {}, for Epoch {} and Layer {}\".format(state, str(ID), str(epoch), str(layer)))\n",
    "\n",
    "    if state == 'forward':\n",
    "        # Forward propagation from A0 to Cost\n",
    "        # Activations from the previous layer\n",
    "        A_prev = from_cache(endpoint=endpoint, key=parameters['data_keys']['A'+str(layer - 1)])\n",
    "        # Get the weights for this neuron\n",
    "        w = from_cache(endpoint=endpoint, key=parameters['data_keys']['W'+str(layer)])[ID-1, :]\n",
    "        # Convert weights to a row vector\n",
    "        w = w.reshape(1, w.shape[0])\n",
    "        # Get the bias for this neuron as row vector\n",
    "        b = from_cache(endpoint=endpoint, key=parameters['data_keys']['b'+str(layer)])[ID-1, :]\n",
    "        # Perform the linear part of the layer's forward propagation\n",
    "        z = np.dot(w, A_prev) + b\n",
    "        # Upload the linear transformation results to ElastiCache for use with Backprop\n",
    "        to_cache(endpoint=endpoint, obj=z, name='layer'+str(layer)+'_z_'+str(ID))\n",
    "\n",
    "        # Perform non-linear activation based on the activation function\n",
    "        if activation == 'sigmoid':\n",
    "            a = sigmoid(z)\n",
    "        elif activation == 'relu':\n",
    "            a = relu(z)\n",
    "        else:\n",
    "            # No other functions supported at this time\n",
    "            pass\n",
    "        # Upload the results to ElastiCache for `TrainerLambda` to vectorize\n",
    "        to_cache(endpoint=endpoint, obj=a, name='layer'+str(layer)+'_a_'+str(ID))\n",
    "\n",
    "        # Debug Statement\n",
    "        #print(\"Completed Forward Propagation for epoch {}, layer {}\".format(str(epoch), str(layer)))\n",
    "        \n",
    "        if last == \"True\":\n",
    "            # Update parameters with this Neuron's data\n",
    "            parameters['epoch'] = epoch\n",
    "            parameters['layer'] = layer + 1\n",
    "            # Build the state payload\n",
    "            payload = {}\n",
    "            payload['parameter_key'] = to_cache(endpoint=endpoint, obj=parameters, name='parameters')\n",
    "            payload['state'] = 'forward'\n",
    "            payload['epoch'] = epoch\n",
    "            payload['layer'] = layer + 1\n",
    "\n",
    "            # Debug Statement\n",
    "            #print(\"Payload to be sent to TrainerLambda: \\n\" + dumps(payload, indent=4, sort_keys=True))\n",
    "            \n",
    "            trainer_handler(event=payload, context='')\n",
    "\n",
    "        return\n",
    "\n",
    "    elif state == 'backward':\n",
    "        # Backprop from Cost to X (A0)\n",
    "        \"\"\"\n",
    "        Intuition: TrainerLambda launched back prop with `layer-1`, therefore this should be \n",
    "        last \"active\" layer. That means that the \"dA\" for this layer has already been\n",
    "        calculate. Thus, no need to do the `A - Y` error calculation. Additionally, \n",
    "        the following code structure makes the it more idempotent for multiple layers.\n",
    "        \"\"\"\n",
    "        # Get necessary parameters\n",
    "        r = redis(host=endpoint, port=6379, db=15, charset=\"utf-8\", decode_responses=True)\n",
    "        z_key = []\n",
    "        for z in r.scan_iter(match='layer'+str(layer)+'_z_'+str(ID)+'*'):\n",
    "            z_key.append(z)\n",
    "        z = from_cache(endpoint=endpoint, key=z_key[0])\n",
    "        m = from_cache(endpoint=endpoint, key=parameters['data_keys']['m'])\n",
    "        A_prev = from_cache(endpoint=endpoint, key=parameters['data_keys']['A'+str(layer-1)])\n",
    "        l2 = parameters['lambda']\n",
    "\n",
    "        # Get the derivative of the current layer's activation,\n",
    "        # based on the size of the layer.\n",
    "        if layer == parameters['layers']:\n",
    "            # If this is the last layer, then:\n",
    "            dA = from_cache(endpoint=endpoint, key=parameters['data_keys']['dA'+str(layer)])\n",
    "            W = from_cache(endpoint=endpoint, key=parameters['data_keys']['W'+str(layer)])\n",
    "        else:\n",
    "            dA = from_cache(endpoint=endpoint, key=parameters['data_keys']['dA'+str(layer)])[ID-1, :]\n",
    "            dA = dA.reshape(1, dA.shape[0])\n",
    "            W = from_cache(endpoint=endpoint, key=parameters['data_keys']['W'+str(layer)])[ID-1, :]\n",
    "            W = W.reshape(1, W.shape[0])\n",
    "        \n",
    "        # Calculate the derivative of the Activations\n",
    "        if activation=='sigmoid':\n",
    "            dZ = sigmoid_backward(dA, z)\n",
    "        elif activation == 'relu':\n",
    "            dZ = relu_backward(dA, z)\n",
    "        elif activaion == 'leaky_relu':\n",
    "            dZ = leaky_relu_backward(dA, z)\n",
    "        else:\n",
    "            # No other functions supported at this time\n",
    "            pass\n",
    "        # Upload the derivative of the activation to ElastiCache for use by `TrainerLambda`\n",
    "        to_cache(endpoint=endpoint, obj=dZ, name='layer'+str(layer)+'_dZ_'+str(ID))\n",
    "        \n",
    "        # Calculate the derivatives of the weights\n",
    "        #dw = 1 / m * np.dot(dZ, A_prev.T)\n",
    "        # Calculate the derivatives of the weights with L2 Regularization\n",
    "        dw = 1 / m * (np.dot(dZ, A_prev.T) + l2 * W)\n",
    "        # Upload the derivative of the weights to ElastiCache for use by `TrainerLambda`\n",
    "        to_cache(endpoint=endpoint, obj=dw, name='layer'+str(layer)+'_dw_'+str(ID))\n",
    "        \n",
    "        # Debug statement\n",
    "        assert(dw.shape == W.shape)\n",
    "\n",
    "        # Calculate the derivatives of the bias\n",
    "        db = 1 / m * np.sum(dZ, axis=1, keepdims=True)\n",
    "        # Upload the derivative of the bis to ElastiCache for use by `TrainerLambda`\n",
    "        to_cache(endpoint=endpoint, obj=db, name='layer'+str(layer)+'_db_'+str(ID))\n",
    "\n",
    "        # Debug Statement\n",
    "        #print(\"Completed Back Propogation for epoch {}, layer {}\".format(str(epoch), str(layer)))\n",
    "\n",
    "        if last == \"True\":\n",
    "            # Update parameters with this Neuron's data\n",
    "            parameters['epoch'] = epoch\n",
    "            parameters['layer'] = layer - 1\n",
    "            # Build the state payload\n",
    "            payload = {}\n",
    "            payload['parameter_key'] = to_cache(endpoint=endpoint, obj=parameters, name='parameters')\n",
    "            payload['state'] = 'backward'\n",
    "            payload['epoch'] = epoch\n",
    "            payload['layer'] = layer - 1\n",
    "\n",
    "            # Debug Statement\n",
    "            #print(\"Payload to be sent to TrainerLambda: \\n\" + dumps(payload, indent=4, sort_keys=True))\n",
    "            \n",
    "            trainer_handler(event=payload, context='')\n",
    "            \n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Sample Model Training\n",
    "### Overview\n",
    "The following demonstrates training the model for a *2-Layer* Network over $10$ Epochs. The final results are stored on S3 and can be analyzed after training has been completed.\n",
    "\n",
    "### 1 - Trigger Event from S3\n",
    "**Simulate the training data being uploaded to S3 and Launching the training process.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Simulate S3 event trigger data\n",
    "launch_handler(event, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - View the Training Results\n",
    "Althoug there are only $10$ iterations of the model training process, the cost should decrease after every epoch and can be visualized as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# View the Results object stored on S3\n",
    "bucket = parameters['s3_bucket']\n",
    "content = s3_resource.Object(bucket, 'training_results/results.json')\n",
    "file = content.get()['Body'].read().decode('utf-8')\n",
    "json_content = json.loads(file)\n",
    "#print(json_content)\n",
    "costs = []\n",
    "for k, v in json_content.items():\n",
    "    # Get the cost at each epoch\n",
    "    if 'epoch' in k:\n",
    "        costs.append(v.get('cost'))\n",
    "    # Get the training start time\n",
    "    elif 'Start' in k:\n",
    "        start = datetime.datetime.strptime(v, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    # Get the training end time\n",
    "    else:\n",
    "        end = datetime.datetime.strptime(v, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "delta = end - start\n",
    "print(\"Total Processing time: {} minutes\".format(int(delta.total_seconds() / 60)))\n",
    "plt.plot(costs)\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title(\"Learning Rate: \" + str(parameters['learning_rate']))\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next: Full Model Training\n",
    "Now that model training process (and code) can be verified, it's time to train the model using the  serverless framework. Please refer to the [**README**](../README.md) on how to start the training process and then [**Analyze**](./Analysis.ipynb) the results."
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "XaIWT",
   "launcher_item_id": "zAgPl"
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
