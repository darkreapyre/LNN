{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Model Training and Prediction\n",
    "## Introduction\n",
    "__\"Leverage SageMaker from Notebook --> Production Testing\"__\n",
    "\n",
    "---\n",
    "## 1 - Model Training\n",
    "### Permissions and Environmental Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "#from __future__ import print_function\n",
    "import os\n",
    "import io\n",
    "import boto3\n",
    "import sagemaker\n",
    "import h5py\n",
    "import json\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from sagemaker.mxnet import MXNet\n",
    "from mxnet import gluon\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Confifuree SageMaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-east-1-722812380636\n"
     ]
    }
   ],
   "source": [
    "# Create local repository for Numpy Arrays\n",
    "if not os.path.exists('/tmp/data'):\n",
    "    os.mkdir('/tmp/data')\n",
    "\n",
    "# Load the Training and Testing dataset\n",
    "dataset = h5py.File('datasets/datasets.h5', 'r')\n",
    "\n",
    "# Save the Dataset as Numpy Arrays\n",
    "np.save('/tmp/data/train_X.npy', np.array(dataset['train_set_x'][:]))\n",
    "np.save('/tmp/data/train_Y.npy', np.array(dataset['train_set_y'][:]))\n",
    "np.save('/tmp/data/test_X.npy', np.array(dataset['test_set_x'][:]))\n",
    "np.save('/tmp/data/test_Y.npy', np.array(dataset['test_set_y'][:]))\n",
    "\n",
    "# Upload the Training and Testing Data to S3\n",
    "inputs = sagemaker_session.upload_data(path='/tmp/data', key_prefix='training_input')\n",
    "bucket = inputs.split('/')[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create the Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MXNet Estimator\n",
    "mxnet_estimator = MXNet(\n",
    "    'model.py',\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.xlarge',\n",
    "    output_path='s3://'+bucket,\n",
    "    hyperparameters={\n",
    "        'epochs': 2500,\n",
    "        'optmizer': 'sgd',\n",
    "        'learning_rate': 0.0075,\n",
    "        'batch_size': 64\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-east-1-722812380636\n",
      "INFO:sagemaker:Creating training-job with name: sagemaker-mxnet-2018-04-10-22-56-46-817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py:623: DeprecationWarning: generator 'multi_stream_iter' raised StopIteration\n",
      "  for idx, event in sagemaker.logs.multi_stream_iter(client, log_group, stream_names, positions):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m2018-04-10 23:01:09,001 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2018-04-10 23:01:09,001 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2018-04-10 23:01:09,007 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[31m2018-04-10 23:01:11,142 INFO - mxnet_container.train - MXNetTrainingEnvironment: {'enable_cloudwatch_metrics': False, 'available_gpus': 0, 'channels': {u'training': {u'TrainingInputMode': u'File', u'RecordWrapperType': u'None', u'S3DistributionType': u'FullyReplicated'}}, '_ps_verbose': 0, 'resource_config': {u'current_host': u'algo-1', u'hosts': [u'algo-1']}, 'user_script_name': u'model.py', 'input_config_dir': '/opt/ml/input/config', 'channel_dirs': {u'training': u'/opt/ml/input/data/training'}, 'code_dir': '/opt/ml/code', 'output_data_dir': '/opt/ml/output/data/', 'output_dir': '/opt/ml/output', 'model_dir': '/opt/ml/model', 'hyperparameters': {u'sagemaker_program': u'model.py', u'learning_rate': 0.0075, u'batch_size': 64, u'epochs': 2500, u'optmizer': u'sgd', u'sagemaker_submit_directory': u's3://sagemaker-us-east-1-722812380636/sagemaker-mxnet-2018-04-10-22-56-46-817/source/sourcedir.tar.gz', u'sagemaker_region': u'us-east-1', u'sagemaker_enable_cloudwatch_metrics': False, u'sagemaker_job_name': u'sagemaker-mxnet-2018-04-10-22-56-46-817', u'sagemaker_container_log_level': 20}, 'hosts': [u'algo-1'], '_scheduler_ip': '10.32.0.4', '_ps_port': 8000, 'user_script_archive': u's3://sagemaker-us-east-1-722812380636/sagemaker-mxnet-2018-04-10-22-56-46-817/source/sourcedir.tar.gz', '_scheduler_host': u'algo-1', 'sagemaker_region': u'us-east-1', 'input_dir': '/opt/ml/input', 'user_requirements_file': None, 'current_host': u'algo-1', 'container_log_level': 20, 'available_cpus': 4, 'base_dir': '/opt/ml'}\u001b[0m\n",
      "\u001b[31mDownloading s3://sagemaker-us-east-1-722812380636/sagemaker-mxnet-2018-04-10-22-56-46-817/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[31m2018-04-10 23:01:11,261 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTP connection (1): 169.254.170.2\u001b[0m\n",
      "\u001b[31m2018-04-10 23:01:11,383 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): sagemaker-us-east-1-722812380636.s3.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-04-10 23:01:11,505 INFO - mxnet_container.train - Starting distributed training task\u001b[0m\n",
      "\u001b[31mEpoch: 0; Loss: 0.695138465845; Train-accuracy = 0.622009569378; Validation-accuracy = 0.36\u001b[0m\n",
      "\u001b[31mEpoch: 100; Loss: 0.597045026898; Train-accuracy = 0.755980861244; Validation-accuracy = 0.42\u001b[0m\n",
      "\u001b[31mEpoch: 200; Loss: 0.410969414779; Train-accuracy = 0.732057416268; Validation-accuracy = 0.82\u001b[0m\n",
      "\u001b[31mEpoch: 300; Loss: 0.308308281967; Train-accuracy = 0.583732057416; Validation-accuracy = 0.74\u001b[0m\n",
      "\u001b[31mEpoch: 400; Loss: 0.0463159141358; Train-accuracy = 0.923444976077; Validation-accuracy = 0.78\u001b[0m\n",
      "\u001b[31mEpoch: 500; Loss: 0.0119214219768; Train-accuracy = 1.0; Validation-accuracy = 0.76\u001b[0m\n",
      "\u001b[31mEpoch: 600; Loss: 0.00537486723736; Train-accuracy = 1.0; Validation-accuracy = 0.72\u001b[0m\n",
      "\u001b[31mEpoch: 700; Loss: 0.00387620736965; Train-accuracy = 1.0; Validation-accuracy = 0.72\u001b[0m\n",
      "\u001b[31mEpoch: 800; Loss: 0.00267517728883; Train-accuracy = 1.0; Validation-accuracy = 0.74\u001b[0m\n",
      "\u001b[31mEpoch: 900; Loss: 0.00192852433254; Train-accuracy = 1.0; Validation-accuracy = 0.72\u001b[0m\n",
      "\u001b[31mEpoch: 1000; Loss: 0.0015040812702; Train-accuracy = 1.0; Validation-accuracy = 0.74\u001b[0m\n",
      "\u001b[31mEpoch: 1100; Loss: 0.00122630519516; Train-accuracy = 1.0; Validation-accuracy = 0.74\u001b[0m\n",
      "\u001b[31mEpoch: 1200; Loss: 0.00102340535631; Train-accuracy = 1.0; Validation-accuracy = 0.74\u001b[0m\n",
      "\u001b[31mEpoch: 1300; Loss: 0.000866747953657; Train-accuracy = 1.0; Validation-accuracy = 0.72\u001b[0m\n",
      "\u001b[31mEpoch: 1400; Loss: 0.00075065733143; Train-accuracy = 1.0; Validation-accuracy = 0.72\u001b[0m\n",
      "\u001b[31mEpoch: 1500; Loss: 0.000661372639346; Train-accuracy = 1.0; Validation-accuracy = 0.72\u001b[0m\n",
      "\u001b[31mEpoch: 1600; Loss: 0.000590120036708; Train-accuracy = 1.0; Validation-accuracy = 0.72\u001b[0m\n",
      "\u001b[31mEpoch: 1700; Loss: 0.000532360680615; Train-accuracy = 1.0; Validation-accuracy = 0.72\u001b[0m\n",
      "\u001b[31mEpoch: 1800; Loss: 0.0004837773161; Train-accuracy = 1.0; Validation-accuracy = 0.72\u001b[0m\n",
      "\u001b[31mEpoch: 1900; Loss: 0.000443678643358; Train-accuracy = 1.0; Validation-accuracy = 0.72\u001b[0m\n",
      "\u001b[31mEpoch: 2000; Loss: 0.000407625072186; Train-accuracy = 1.0; Validation-accuracy = 0.72\u001b[0m\n",
      "\u001b[31mEpoch: 2100; Loss: 0.000379648721336; Train-accuracy = 1.0; Validation-accuracy = 0.72\u001b[0m\n",
      "\u001b[31mEpoch: 2200; Loss: 0.000351587760498; Train-accuracy = 1.0; Validation-accuracy = 0.72\u001b[0m\n",
      "\u001b[31mEpoch: 2300; Loss: 0.000329501328669; Train-accuracy = 1.0; Validation-accuracy = 0.72\u001b[0m\n",
      "\u001b[31mEpoch: 2400; Loss: 0.000309359665479; Train-accuracy = 1.0; Validation-accuracy = 0.72\u001b[0m\n",
      "\u001b[31mEpoch: 2499; Loss: 0.000291017717437; Train-accuracy = 1.0; Validation-accuracy = 0.72\u001b[0m\n",
      "\u001b[31mSaving the training results ...\u001b[0m\n",
      "\u001b[31mSaving the trained model ...\u001b[0m\n",
      "===== Job Complete =====\n",
      "Billable seconds: 272\n"
     ]
    }
   ],
   "source": [
    "# Create a new Job name for current training run\n",
    "#job_name = '<<Specific Training Job Name'\n",
    "#mxnet_estimator.fit(inputs, job_name=job_name)\n",
    "mxnet_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "## 2 - Training Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (404) when calling the HeadObject operation: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ab9eab2626d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mjob_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'<<Enter Training Job Name>>'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0ms3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m's3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/output/output.tar.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/tmp/output.tar.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp/output.tar.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/boto3/s3/inject.py\u001b[0m in \u001b[0;36mbucket_download_file\u001b[0;34m(self, Key, Filename, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    166\u001b[0m     return self.meta.client.download_file(\n\u001b[1;32m    167\u001b[0m         \u001b[0mBucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         ExtraArgs=ExtraArgs, Callback=Callback, Config=Config)\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/boto3/s3/inject.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(self, Bucket, Key, Filename, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    128\u001b[0m         return transfer.download_file(\n\u001b[1;32m    129\u001b[0m             \u001b[0mbucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             extra_args=ExtraArgs, callback=Callback)\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/boto3/s3/transfer.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(self, bucket, key, filename, extra_args, callback)\u001b[0m\n\u001b[1;32m    305\u001b[0m             bucket, key, filename, extra_args, subscribers)\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;31m# This is for backwards compatibility where when retries are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;31m# exceeded we need to throw the same error from boto3 instead of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/s3transfer/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;31m# however if a KeyboardInterrupt is raised we want want to exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;31m# out of this and propogate the exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/s3transfer/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# final result.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/s3transfer/tasks.py\u001b[0m in \u001b[0;36m_main\u001b[0;34m(self, transfer_future, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;31m# Call the submit method to start submitting tasks to execute the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;31m# transfer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;31m# If there was an exception raised during the submission of task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/s3transfer/download.py\u001b[0m in \u001b[0;36m_submit\u001b[0;34m(self, client, config, osutil, request_executor, io_executor, transfer_future, bandwidth_limiter)\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0mBucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0mKey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m             )\n\u001b[1;32m    355\u001b[0m             transfer_future.meta.provide_transfer_size(\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    313\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (404) when calling the HeadObject operation: Not Found"
     ]
    }
   ],
   "source": [
    "# Download and uncompress output results from model training\n",
    "import tarfile, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "job_name = '<<Enter Training Job Name>>'\n",
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(bucket).download_file(job_name+'/output/output.tar.gz', '/tmp/output.tar.gz')\n",
    "tarfile.open('/tmp/output.tar.gz').extractall()\n",
    "with open('results.json') as j:\n",
    "    data = json.load(j)#, object_pairs_hook=OrderedDict)\n",
    "\n",
    "# Format data for plotting\n",
    "costs = []\n",
    "val_acc = []\n",
    "train_acc = []\n",
    "for key, value in sorted(data.items()):#, key=lambda (k,v): (v, k)):\n",
    "    if 'epoch' in key:\n",
    "        for k, v in value.items():\n",
    "            if k == 'cost':\n",
    "                costs.append(v)\n",
    "            elif k == 'val_acc':\n",
    "                val_acc.append(v)\n",
    "            elif k == 'train_acc':\n",
    "                train_acc.append(v)\n",
    "    elif 'Start' in key:\n",
    "        start = datetime.datetime.strptime(value, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    elif 'End' in key:\n",
    "        end = datetime.datetime.strptime(value, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "val_acc = np.array(val_acc)\n",
    "train_acc = np.array(train_acc)\n",
    "costs = np.array(costs)\n",
    "delta = end - start\n",
    "print(\"Model Training Time: {} Minute(s)\".format(int(delta.total_seconds() / 60)))\n",
    "\n",
    "# Plot the Learning Curve\n",
    "plt.rcParams['figure.figsize'] = (11.0, 10.0)\n",
    "plt.plot(costs)\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.ylabel('Cost / Accuracy')\n",
    "plt.xlabel('Epochs (in Hundreds)')\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(['Cost', 'Training Accuracy', 'Validation Accuracy'])\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "## 3 - Prediciton Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = mxnet_estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Test prediction on unseen image data.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "from skimage import transform\n",
    "%matplotlib inline\n",
    "\n",
    "# Get Classes\n",
    "classes = [\"non-cat\", \"cat\"]\n",
    "\n",
    "# Get Image files\n",
    "images = []\n",
    "for img_path in glob.glob('./images/*'):\n",
    "    images.append(mpimg.imread(img_path))\n",
    "\n",
    "# Plot predictions\n",
    "plt.figure(figsize=(20.0,20.0))\n",
    "columns = 2\n",
    "for i, image in enumerate(images):\n",
    "    img = transform.resize(image, (64, 64), mode='constant').reshape((1, 64 * 64 * 3))\n",
    "    prediction = int(predictor.predict(img.tolist()))\n",
    "    plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
    "    plt.title('Prediction = \"{}\" picture.'.format(classes[prediction]))\n",
    "    plt.imshow(image);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
