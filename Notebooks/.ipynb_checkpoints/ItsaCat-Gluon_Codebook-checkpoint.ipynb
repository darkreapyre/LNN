{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Model Training and Prediction\n",
    "## Introduction\n",
    "__\"Leverage SageMaker from Notebook --> Production Testing\"__\n",
    "\n",
    "---\n",
    "## 1 - Model Training\n",
    "### Permissions and Environmental Variables\n",
    "\n",
    "The packages that will be needed to prepare the data and train the model are as follows:\n",
    "- [os](https://docs.python.org/3/library/os.html) provides a portable way of using operating system dependent functionality to manage the data set locally before uploading to the S3.\n",
    "- [datetime](https://docs.python.org/2/library/datetime.html) provides classes for manipulating dates and times in both simple and complex ways.\n",
    "- [numpy](https://www.numpy.org) is the fundamental package for scientific computing with Python.\n",
    "- [matplotlib](https://matplotlib.org) is a famous library to plot graphs in Python.\n",
    "- [PIL](http://www.pythonware.com/products/pil/) is used here to test the model with your own picture at the end.\n",
    "boto3 is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python, which allows Python developers to write software that makes use of services like Amazon S3 and Amazon EC2.\n",
    "json is a lightweight data interchange format inspired by JavaScript object literal syntax (although it is not a strict subset of JavaScript.\n",
    "os is a module the provides a portable way of using operating system dependent functionality. Particularly the  environ object is a mapping object representing the environment.\n",
    "uuid creates a unique, random ID.\n",
    "The io module provides the Python interfaces to stream handling.\n",
    "The Python interface to the Redis key-value store.\n",
    "math to determine the last mini-batch size when partitioning the Training Data Set into mini-batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import h5py\n",
    "import json\n",
    "import tarfile\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from sagemaker.mxnet import MXNet\n",
    "from mxnet import gluon\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Configure SageMaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create local repository for Numpy Arrays\n",
    "if not os.path.exists('/tmp/data'):\n",
    "    os.mkdir('/tmp/data')\n",
    "\n",
    "# Load the Training and Testing dataset\n",
    "dataset = h5py.File('datasets/datasets.h5', 'r')\n",
    "\n",
    "# Save the Dataset as Numpy Arrays\n",
    "np.save('/tmp/data/train_X.npy', np.array(dataset['train_set_x'][:]))\n",
    "np.save('/tmp/data/train_Y.npy', np.array(dataset['train_set_y'][:]))\n",
    "np.save('/tmp/data/test_X.npy', np.array(dataset['test_set_x'][:]))\n",
    "np.save('/tmp/data/test_Y.npy', np.array(dataset['test_set_y'][:]))\n",
    "\n",
    "# Upload the Training and Testing Data to S3\n",
    "inputs = sagemaker_session.upload_data(path='/tmp/data', key_prefix='training_input')\n",
    "bucket = inputs.split('/')[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create the Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MXNet Estimator\n",
    "mxnet_estimator = MXNet(\n",
    "    'model.py',\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.xlarge',\n",
    "    output_path='s3://'+bucket,\n",
    "    hyperparameters={\n",
    "        'epochs': 2500,\n",
    "        'optmizer': 'sgd',\n",
    "        'learning_rate': 0.0075,\n",
    "        'batch_size': 64\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Job name for current training run\n",
    "#job_name = '<<Specific Training Job Name'\n",
    "#mxnet_estimator.fit(inputs, job_name=job_name)\n",
    "mxnet_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "## 2 - Training Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and uncompress output results from model training\n",
    "%matplotlib inline\n",
    "job_name = '<<Enter Training Job Name>>'\n",
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(bucket).download_file(job_name+'/output/output.tar.gz', '/tmp/output.tar.gz')\n",
    "tarfile.open('/tmp/output.tar.gz').extractall()\n",
    "with open('results.json') as j:\n",
    "    data = json.load(j)#, object_pairs_hook=OrderedDict)\n",
    "\n",
    "# Format data for plotting\n",
    "costs = []\n",
    "val_acc = []\n",
    "train_acc = []\n",
    "for key, value in sorted(data.items()):#, key=lambda (k,v): (v, k)):\n",
    "    if 'epoch' in key:\n",
    "        for k, v in value.items():\n",
    "            if k == 'cost':\n",
    "                costs.append(v)\n",
    "            elif k == 'val_acc':\n",
    "                val_acc.append(v)\n",
    "            elif k == 'train_acc':\n",
    "                train_acc.append(v)\n",
    "    elif 'Start' in key:\n",
    "        start = datetime.datetime.strptime(value, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    elif 'End' in key:\n",
    "        end = datetime.datetime.strptime(value, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "val_acc = np.array(val_acc)\n",
    "train_acc = np.array(train_acc)\n",
    "costs = np.array(costs)\n",
    "delta = end - start\n",
    "print(\"Model Training Time: {} Minute(s)\".format(int(delta.total_seconds() / 60)))\n",
    "\n",
    "# Plot the Learning Curve\n",
    "plt.rcParams['figure.figsize'] = (11.0, 10.0)\n",
    "plt.plot(costs)\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.ylabel('Cost / Accuracy')\n",
    "plt.xlabel('Epochs (in Hundreds)')\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(['Cost', 'Training Accuracy', 'Validation Accuracy'])\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "## 3 - Prediciton Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = mxnet_estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Test prediction on unseen image data.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "from skimage import transform\n",
    "\n",
    "# Get Classes\n",
    "classes = [\"non-cat\", \"cat\"]\n",
    "\n",
    "# Get Image files\n",
    "images = []\n",
    "for img_path in glob.glob('./images/*'):\n",
    "    images.append(mpimg.imread(img_path))\n",
    "\n",
    "# Plot predictions\n",
    "plt.figure(figsize=(20.0,20.0))\n",
    "columns = 2\n",
    "for i, image in enumerate(images):\n",
    "    img = transform.resize(image, (64, 64), mode='constant').reshape((1, 64 * 64 * 3))\n",
    "    prediction = int(predictor.predict(img.tolist()))\n",
    "    plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
    "    plt.title('Prediction = \"{}\" picture.'.format(classes[prediction]))\n",
    "    plt.imshow(image);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
