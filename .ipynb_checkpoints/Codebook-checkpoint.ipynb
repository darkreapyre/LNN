{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Model Training and Predition\n",
    "## Introduction\n",
    "\"Leverage SageMaker for manual data science process.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1 - Model Training\n",
    "### Permissions and Environmental Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import io\n",
    "import boto3\n",
    "import sagemaker\n",
    "import h5py\n",
    "import json\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from sagemaker.mxnet import MXNet\n",
    "from mxnet import gluon\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Confifure SageMaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create local repository for Numpy Arrays\n",
    "if not os.path.exists('tmp'): os.mkdir('tmp')\n",
    "\n",
    "# Load the Training and Testing dataset\n",
    "dataset = h5py.File('datasets/datasets.h5', 'r')\n",
    "\n",
    "# Save the Dataset as Numpy Arrays\n",
    "np.save('tmp/train_X.npy', np.array(dataset['train_set_x'][:]))\n",
    "np.save('tmp/train_Y.npy', np.array(dataset['train_set_y'][:]))\n",
    "\n",
    "# Upload the Training and Testing Data to S3\n",
    "inputs = sagemaker_session.upload_data(path='tmp', key_prefix='training_input')\n",
    "bucket = inputs.split('/')[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create the Estimator using the SageMaker Python Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mxnet_estimator = MXNet(\n",
    "    'model.py',\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.xlarge',\n",
    "    output_path='s3://'+bucket,\n",
    "    hyperparameters={\n",
    "        'epochs': 2500,\n",
    "        'optmizer': 'sgd',\n",
    "        'learning_rate': 0.0075,\n",
    "        'batch_size': 64\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mxnet_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "## 2 - Model Analysis\n",
    "\n",
    "`<<Bucket>>/<<Job Name>>/output/`\n",
    "- Model\n",
    "- Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the S3 Bucket Name and Region used during training\n",
    "#S3_bucket = <<Bucket Name>>\n",
    "#rgn = <<AWS Region>>\n",
    "#job_name = <<SageMaker Job Name>>\n",
    "rgn = 'us-west-2'\n",
    "job_name = 'sagemaker-mxnet-py2-cpu-2018-03-31-04-49-38-166'\n",
    "\n",
    "# Download and uncompress output results from model training\n",
    "import tarfile, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(bucket).download_file(job_name+'/output/output.tar.gz', './output.tar.gz')\n",
    "tarfile.open('./output.tar.gz').extractall()\n",
    "with open('results.json') as j:\n",
    "    data = json.load(j)#, object_pairs_hook=OrderedDict)\n",
    "\n",
    "# Format data for plotting\n",
    "costs = []\n",
    "for key, value in sorted(data.iteritems(), key=lambda (k,v): (v, k)):\n",
    "    if 'epoch' in key:\n",
    "        costs.append(value)\n",
    "    elif 'Start' in key:\n",
    "        start = datetime.datetime.strptime(value, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    else:\n",
    "        end = datetime.datetime.strptime(value, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "delta = end - start\n",
    "costs.reverse()\n",
    "print(\"Total Processing time: {} Minute(s)\".format(int(delta.total_seconds() / 60)))\n",
    "\n",
    "# Plot the results\n",
    "plt.rcParams['figure.figsize'] = (11.0, 10.0)\n",
    "plt.plot(costs)\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next: DevOps Process Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p27",
   "language": "python",
   "name": "conda_mxnet_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
