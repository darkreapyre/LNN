{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import h5py\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "dataset = h5py.File('datasets/datasets.h5', 'r')\n",
    "train_set_x_orig = mx.nd.array(dataset['train_set_x'][:])\n",
    "train_set_y_orig = mx.nd.array(dataset['train_set_y'][:])\n",
    "test_set_x_orig = mx.nd.array(dataset['test_set_x'][:])\n",
    "test_set_y_orig = mx.nd.array(dataset['test_set_y'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 64, 64, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_x_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(x):\n",
    "    v = x.reshape((x.shape[0], (x.shape[1] * x.shape[2]) * x.shape[3]))\n",
    "    return v.astype(np.float32) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = transform(train_set_x_orig)\n",
    "label = train_set_y_orig.astype(np.float32)\n",
    "test_data = transform(test_set_x_orig)\n",
    "test_label = test_set_y_orig.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 12288)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 209\n",
    "trainer_iter = mx.io.NDArrayIter(data, label, batch_size=batch_size, shuffle=False)\n",
    "val_iter = mx.io.NDArrayIter(test_data, test_label)\n",
    "#trainer_iter = mx.io.NDArrayIter(np.random.randn(209, 12288), label=np.random.randn(209,), batch_size=209)\n",
    "#val_iter = mx.io.NDArrayIter(np.zeros((50, 12288)), label=np.zeros((50,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = mx.sym.var('data')\n",
    "#data = mx.sym.flatten(data=data)\n",
    "fc1 = mx.sym.FullyConnected(data=data, num_hidden=20)\n",
    "act1 = mx.sym.Activation(data=fc1, act_type='relu')\n",
    "fc2 = mx.sym.FullyConnected(data=act1, num_hidden=7)\n",
    "act2 = mx.sym.Activation(data=fc2, act_type='relu')\n",
    "fc3 = mx.sym.FullyConnected(data=act2, num_hidden=5)\n",
    "act3 = mx.sym.Activation(data=fc3, act_type=\"relu\")\n",
    "fc4 = mx.sym.FullyConnected(data=act3, num_hidden=1)\n",
    "#act4 = mx.sym.Activation(data=fc4, act_type='sigmoid')\n",
    "out = mx.sym.LogisticRegressionOutput(data=fc4, name='softmax')\n",
    "#mx.viz.plot_network(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Intermediate level API__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training ('loss', 0.53440561248925311)\n",
      "Epoch 100, Training ('loss', 0.48359541459517047)\n",
      "Epoch 200, Training ('loss', 0.47309787878009119)\n",
      "Epoch 300, Training ('loss', 0.47821694698059958)\n",
      "Epoch 400, Training ('loss', 0.49147621410315118)\n",
      "Epoch 500, Training ('loss', 0.481479918557491)\n",
      "Epoch 600, Training ('loss', 0.48924215216385691)\n",
      "Epoch 700, Training ('loss', 0.48965468703274523)\n",
      "Epoch 800, Training ('loss', 0.49024375659997382)\n",
      "Epoch 900, Training ('loss', 0.48392727500513982)\n",
      "Epoch 1000, Training ('loss', 0.48117875824704692)\n",
      "Epoch 1100, Training ('loss', 0.48130002546538575)\n",
      "Epoch 1200, Training ('loss', 0.47072101209722639)\n",
      "Epoch 1300, Training ('loss', 0.46221438321200287)\n",
      "Epoch 1400, Training ('loss', 0.45168906763980265)\n",
      "Epoch 1500, Training ('loss', 0.44834604217675311)\n",
      "Epoch 1600, Training ('loss', 0.44284550424968228)\n",
      "Epoch 1700, Training ('loss', 0.43665594803659541)\n",
      "Epoch 1800, Training ('loss', 0.42857251327003587)\n",
      "Epoch 1900, Training ('loss', 0.42566487435518841)\n",
      "Epoch 2000, Training ('loss', 0.42083893552351226)\n",
      "Epoch 2100, Training ('loss', 0.41798404529334254)\n",
      "Epoch 2200, Training ('loss', 0.41260999469665821)\n",
      "Epoch 2300, Training ('loss', 0.41084921074826181)\n",
      "Epoch 2400, Training ('loss', 0.4074156911749589)\n",
      "Epoch 2500, Training ('loss', 0.40452546480169704)\n",
      "Epoch 2600, Training ('loss', 0.4020811747135728)\n",
      "Epoch 2700, Training ('loss', 0.3996410461133747)\n",
      "Epoch 2800, Training ('loss', 0.39766393780137932)\n",
      "Epoch 2900, Training ('loss', 0.39535551664361546)\n"
     ]
    }
   ],
   "source": [
    "mod = mx.mod.Module(symbol=out,\n",
    "                    context=mx.cpu(),\n",
    "                    data_names=['data'],\n",
    "                    label_names=['softmax_label']\n",
    "                   )\n",
    "# allocate memory given the input data and label shapes\n",
    "mod.bind(data_shapes=trainer_iter.provide_data, label_shapes=trainer_iter.provide_label)\n",
    "# initialize parameters by uniform random numbers\n",
    "mod.init_params(initializer=mx.init.Xavier(magnitude=2.))\n",
    "# use SGD with learning rate 0.1 to train\n",
    "mod.init_optimizer(optimizer='sgd', optimizer_params=(('learning_rate', 0.0075), ))\n",
    "# use accuracy as the metric\n",
    "accuracy = mx.metric.Accuracy()\n",
    "ce_loss = mx.metric.CrossEntropy()\n",
    "#metric = mx.metric.CompositeEvalMetric([accuracy, ce_loss])\n",
    "metric = mx.metric.Loss()\n",
    "# train 5 epochs, i.e. going over the data iter one pass\n",
    "for epoch in range(3000):\n",
    "    trainer_iter.reset()\n",
    "    metric.reset()\n",
    "    for batch in trainer_iter:\n",
    "        mod.forward(batch, is_train=True)       # compute predictions\n",
    "        mod.update_metric(metric, batch.label)  # accumulate prediction accuracy\n",
    "        mod.backward()                          # compute gradients\n",
    "        mod.update()                            # update parameters\n",
    "    if epoch % 100 ==0:\n",
    "        print('Epoch %d, Training %s' % (epoch, metric.get()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('accuracy', 0.34000000000000002)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.score(val_iter, mx.metric.Accuracy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "```python\n",
    "mlp_model = mx.mod.Module(symbol=out, context=mx.cpu())\n",
    "mlp_model.fit(\n",
    "    trainer_iter,\n",
    "    eval_data=val_iter,\n",
    "    optimizer='sgd',\n",
    "    optimizer_params={'learning_rate':0.0075},\n",
    "    eval_metric='loss',\n",
    "    batch_end_callback = mx.callback.Speedometer(batch_size, 100),\n",
    "    num_epoch=10\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
