{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L-Layer Testing\n",
    "## Architecture\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"epochs\": 1,\n",
    "    \"layers\": 2,\n",
    "    \"activations\": {\n",
    "        \"layer1\": \"sigmoid\",\n",
    "        \"layer2\": \"relu\"\n",
    "    },\n",
    "    \"neurons\": {\n",
    "        \"layer1\": 3,\n",
    "        \"layer2\": 1\n",
    "    },\n",
    "    \"weight\": 0.01,\n",
    "    \"bias\": 0,\n",
    "    \"learning_rate\": 0.005\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "## Forward Propogation\n",
    "### S3 Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ''\n",
    "# Simulate S3 event trigger data\n",
    "event = {\n",
    "    \"Records\": [\n",
    "        {\n",
    "            \"eventVersion\": \"2.0\",\n",
    "            \"eventTime\": \"1970-01-01T00:00:00.000Z\",\n",
    "            \"requestParameters\": {\n",
    "                \"sourceIPAddress\": \"127.0.0.1\"\n",
    "             },\n",
    "            \"s3\": {\n",
    "                \"configurationId\": \"testConfigRule\",\n",
    "                \"object\": {\n",
    "                    \"eTag\": \"0123456789abcdef0123456789abcdef\",\n",
    "                    \"sequencer\": \"0A1B2C3D4E5F678901\",\n",
    "                    \"key\": \"training_input/datasets.h5\",\n",
    "                    \"size\": 1024\n",
    "                },\n",
    "                \"bucket\": {\n",
    "                    \"arn\": \"arn:aws:s3:::lnn\",\n",
    "                    \"name\": \"lnn\",\n",
    "                    \"ownerIdentity\": {\n",
    "                        \"principalId\": \"EXAMPLE\"\n",
    "                    }\n",
    "                },\n",
    "                \"s3SchemaVersion\": \"1.0\"\n",
    "            },\n",
    "            \"responseElements\": {\n",
    "                \"x-amz-id-2\": \"EXAMPLE123/5678abcdefghijklambdaisawesome/mnopqrstuvwxyzABCDEFGH\",\n",
    "                \"x-amz-request-id\": \"EXAMPLE123456789\"\n",
    "            },\n",
    "            \"awsRegion\": \"us-west-2\",\n",
    "            \"eventName\": \"ObjectCreated:Put\",\n",
    "            \"userIdentity\": {\n",
    "                \"principalId\": \"EXAMPLE\"\n",
    "            },\n",
    "            \"eventSource\": \"aws:s3\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Neural Network Settings: \n",
      "\n",
      "{\n",
      "    \"activations\": {\n",
      "        \"layer1\": \"relu\",\n",
      "        \"layer2\": \"sigmoid\"\n",
      "    },\n",
      "    \"bias\": 0,\n",
      "    \"data_keys\": {\n",
      "        \"W1\": \"W1|float64#3#12288\",\n",
      "        \"W2\": \"W2|float64#1#3\",\n",
      "        \"b1\": \"b1|float64#3#1\",\n",
      "        \"b2\": \"b2|float64#1#1\",\n",
      "        \"grads\": \"grads|json\",\n",
      "        \"m\": \"m|int\",\n",
      "        \"results\": \"results|json\",\n",
      "        \"test_set_x\": \"test_set_x|float64#12288#50\",\n",
      "        \"test_set_y\": \"test_set_y|int64#1#50\",\n",
      "        \"train_set_x\": \"train_set_x|float64#12288#209\",\n",
      "        \"train_set_y\": \"train_set_y|int64#1#209\"\n",
      "    },\n",
      "    \"dims\": {\n",
      "        \"test_set_x\": [\n",
      "            12288,\n",
      "            50\n",
      "        ],\n",
      "        \"test_set_y\": [\n",
      "            1,\n",
      "            50\n",
      "        ],\n",
      "        \"train_set_x\": [\n",
      "            12288,\n",
      "            209\n",
      "        ],\n",
      "        \"train_set_y\": [\n",
      "            1,\n",
      "            209\n",
      "        ]\n",
      "    },\n",
      "    \"epochs\": 1,\n",
      "    \"input_data\": [\n",
      "        \"train_set_x\",\n",
      "        \"train_set_y\",\n",
      "        \"test_set_x\",\n",
      "        \"test_set_y\"\n",
      "    ],\n",
      "    \"layers\": 2,\n",
      "    \"learning_rate\": 0.005,\n",
      "    \"neurons\": {\n",
      "        \"layer1\": 3,\n",
      "        \"layer2\": 1\n",
      "    },\n",
      "    \"weight\": 0.01\n",
      "}\n",
      "Payload to be sent to TrainerLambda: \n",
      "{\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"start\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import launch\n",
    "from launch import *\n",
    "launch.lambda_handler(event, context)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Launch -> Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event = {\n",
    "    \"parameter_key\": \"parameters|json\",\n",
    "    \"state\": \"start\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Forward Propogation for epoch 0, layer 1\n",
      "Payload to be sent NeuronLambda: \n",
      "{\n",
      "    \"activation\": \"relu\",\n",
      "    \"epoch\": 0,\n",
      "    \"id\": 1,\n",
      "    \"last\": \"False\",\n",
      "    \"layer\": 1,\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"forward\"\n",
      "}\n",
      "Payload to be sent NeuronLambda: \n",
      "{\n",
      "    \"activation\": \"relu\",\n",
      "    \"epoch\": 0,\n",
      "    \"id\": 2,\n",
      "    \"last\": \"False\",\n",
      "    \"layer\": 1,\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"forward\"\n",
      "}\n",
      "Payload to be sent NeuronLambda: \n",
      "{\n",
      "    \"activation\": \"relu\",\n",
      "    \"epoch\": 0,\n",
      "    \"id\": 3,\n",
      "    \"last\": \"True\",\n",
      "    \"layer\": 1,\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"forward\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import trainer\n",
    "from trainer import *\n",
    "trainer.lambda_handler(event, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "### Trainer -> Neuron (Layer 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import neuron\n",
    "from neuron import *\n",
    "\n",
    "event = {\n",
    "    \"1\": {\n",
    "        \"activation\": \"relu\",\n",
    "        \"epoch\": 0,\n",
    "        \"id\": 1,\n",
    "        \"last\": \"False\",\n",
    "        \"layer\": 1,\n",
    "        \"parameter_key\": \"parameters|json\",\n",
    "        \"state\": \"forward\"\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"activation\": \"relu\",\n",
    "        \"epoch\": 0,\n",
    "        \"id\": 2,\n",
    "        \"last\": \"False\",\n",
    "        \"layer\": 1,\n",
    "        \"parameter_key\": \"parameters|json\",\n",
    "        \"state\": \"forward\"\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"activation\": \"relu\",\n",
    "        \"epoch\": 0,\n",
    "        \"id\": 3,\n",
    "        \"last\": \"True\",\n",
    "        \"layer\": 1,\n",
    "        \"parameter_key\": \"parameters|json\",\n",
    "        \"state\": \"forward\"\n",
    "    }\n",
    "}\n",
    "event = dumps(event)\n",
    "event = loads(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "layer = 3\n",
    "parameters = from_cache(endpoint=endpoint, key=\"parameters|json\")\n",
    "if layer == parameters['layers'] + 1:\n",
    "    print(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activations': {'layer1': 'relu', 'layer2': 'sigmoid'},\n",
       " 'bias': 0,\n",
       " 'data_keys': {'W1': 'W1|float64#3#12288',\n",
       "  'W2': 'W2|float64#1#3',\n",
       "  'b1': 'b1|float64#3#1',\n",
       "  'b2': 'b2|float64#1#1',\n",
       "  'grads': 'grads|json',\n",
       "  'm': 'm|int',\n",
       "  'results': 'results|json',\n",
       "  'test_set_x': 'test_set_x|float64#12288#50',\n",
       "  'test_set_y': 'test_set_y|int64#1#50',\n",
       "  'train_set_x': 'train_set_x|float64#12288#209',\n",
       "  'train_set_y': 'train_set_y|int64#1#209'},\n",
       " 'dims': {'test_set_x': [12288, 50],\n",
       "  'test_set_y': [1, 50],\n",
       "  'train_set_x': [12288, 209],\n",
       "  'train_set_y': [1, 209]},\n",
       " 'epoch': 0,\n",
       " 'epochs': 1,\n",
       " 'input_data': ['train_set_x', 'train_set_y', 'test_set_x', 'test_set_y'],\n",
       " 'layer': 1,\n",
       " 'layers': 2,\n",
       " 'learning_rate': 0.005,\n",
       " 'neurons': {'layer1': 3, 'layer2': 1},\n",
       " 'weight': 0.01}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_key = event.get('1')['parameter_key']\n",
    "parameters = from_cache(endpoint=endpoint, key=parameter_key)\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Layer: 1\n",
      "Neuron 1 event:\n",
      "{\"activation\": \"relu\", \"epoch\": 0, \"id\": 1, \"last\": \"False\", \"layer\": 1, \"parameter_key\": \"parameters|json\", \"state\": \"forward\"}\n",
      "Neuron 2 event:\n",
      "{\"activation\": \"relu\", \"epoch\": 0, \"id\": 2, \"last\": \"False\", \"layer\": 1, \"parameter_key\": \"parameters|json\", \"state\": \"forward\"}\n",
      "Payload to be sent to TrainerLambda: \n",
      "{\n",
      "    \"epoch\": 0,\n",
      "    \"layer\": 2,\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"forward\"\n",
      "}\n",
      "Neuron 3 event:\n",
      "{\"activation\": \"relu\", \"epoch\": 0, \"id\": 3, \"last\": \"True\", \"layer\": 1, \"parameter_key\": \"parameters|json\", \"state\": \"forward\"}\n"
     ]
    }
   ],
   "source": [
    "layer = event.get('1')['layer']\n",
    "print(\"Processing Layer: \" + str(layer))\n",
    "event1 = event.get('1')\n",
    "print(\"Neuron 1 event:\\n\" + dumps(event1))\n",
    "neuron.lambda_handler(event=event1, context='')\n",
    "event2 = event.get('2')\n",
    "print(\"Neuron 2 event:\\n\" + dumps(event2))\n",
    "neuron.lambda_handler(event=event2, context='')\n",
    "event3 = event.get('3')\n",
    "neuron.lambda_handler(event=event3, context='')\n",
    "print(\"Neuron 3 event:\\n\" + dumps(event3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Neuron (Layer 1) -> Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Propogating forward onto Layer 2\n",
      "Starting Forward Propogation for epoch 0, layer 2\n",
      "Payload to be sent NeuronLambda: \n",
      "{\n",
      "    \"activation\": \"sigmoid\",\n",
      "    \"epoch\": 0,\n",
      "    \"id\": 1,\n",
      "    \"last\": \"True\",\n",
      "    \"layer\": 2,\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"forward\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import trainer\n",
    "from trainer import *\n",
    "event = {\n",
    "    \"epoch\": 0,\n",
    "    \"layer\": 2,\n",
    "    \"parameter_key\": \"parameters|json\",\n",
    "    \"state\": \"forward\"\n",
    "}\n",
    "trainer.lambda_handler(event, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check: Confirm that `TrainerLambda` processed Layer 1 Activations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activations': {'layer1': 'relu', 'layer2': 'sigmoid'},\n",
       " 'bias': 0,\n",
       " 'data_keys': {'A1': 'A1|float64#3#209',\n",
       "  'W1': 'W1|float64#3#12288',\n",
       "  'W2': 'W2|float64#1#3',\n",
       "  'b1': 'b1|float64#3#1',\n",
       "  'b2': 'b2|float64#1#1',\n",
       "  'grads': 'grads|json',\n",
       "  'm': 'm|int',\n",
       "  'results': 'results|json',\n",
       "  'test_set_x': 'test_set_x|float64#12288#50',\n",
       "  'test_set_y': 'test_set_y|int64#1#50',\n",
       "  'train_set_x': 'train_set_x|float64#12288#209',\n",
       "  'train_set_y': 'train_set_y|int64#1#209'},\n",
       " 'dims': {'test_set_x': [12288, 50],\n",
       "  'test_set_y': [1, 50],\n",
       "  'train_set_x': [12288, 209],\n",
       "  'train_set_y': [1, 209]},\n",
       " 'epoch': 0,\n",
       " 'epochs': 1,\n",
       " 'input_data': ['train_set_x', 'train_set_y', 'test_set_x', 'test_set_y'],\n",
       " 'layer': 2,\n",
       " 'layers': 2,\n",
       " 'learning_rate': 0.005,\n",
       " 'neurons': {'layer1': 3, 'layer2': 1},\n",
       " 'weight': 0.01}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = from_cache(endpoint=endpoint, key='parameters|json')\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 209)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1 = from_cache(endpoint=endpoint, key=parameters['data_keys']['A1'])\n",
    "A1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "### Trainer -> Neuron (Layer 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload to be sent to TrainerLambda: \n",
      "{\n",
      "    \"epoch\": 0,\n",
      "    \"layer\": 3,\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"forward\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import neuron\n",
    "from neuron import *\n",
    "event = {\n",
    "    \"activation\": \"sigmoid\",\n",
    "    \"epoch\": 0,\n",
    "    \"id\": 1,\n",
    "    \"last\": \"True\",\n",
    "    \"layer\": 2,\n",
    "    \"parameter_key\": \"parameters|json\",\n",
    "    \"state\": \"forward\"\n",
    "}\n",
    "neuron.lambda_handler(event, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "### Neuron (Layer 2) -> Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.6933895808784364\n",
      "Starting Backward Propogation for epoch 0, layer 2\n",
      "Payload to be sent to NeuronLambda: \n",
      "{\n",
      "    \"activation\": \"sigmoid\",\n",
      "    \"epoch\": 0,\n",
      "    \"id\": 1,\n",
      "    \"last\": \"True\",\n",
      "    \"layer\": 2,\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"backward\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import trainer\n",
    "from trainer import *\n",
    "event = {\n",
    "    \"epoch\": 0,\n",
    "    \"layer\": 3,\n",
    "    \"parameter_key\": \"parameters|json\",\n",
    "    \"state\": \"forward\"\n",
    "}\n",
    "trainer.lambda_handler(event, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check: Confirm `results` have been updated with the correct cost.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activations': {'layer1': 'relu', 'layer2': 'sigmoid'},\n",
       " 'bias': 0,\n",
       " 'data_keys': {'A1': 'A1|float64#3#209',\n",
       "  'A2': 'A2|float64#1#209',\n",
       "  'W1': 'W1|float64#3#12288',\n",
       "  'W2': 'W2|float64#1#3',\n",
       "  'b1': 'b1|float64#3#1',\n",
       "  'b2': 'b2|float64#1#1',\n",
       "  'dZ2': 'dZ2|float64#1#209',\n",
       "  'grads': 'grads|json',\n",
       "  'm': 'm|int',\n",
       "  'results': 'results|json',\n",
       "  'test_set_x': 'test_set_x|float64#12288#50',\n",
       "  'test_set_y': 'test_set_y|int64#1#50',\n",
       "  'train_set_x': 'train_set_x|float64#12288#209',\n",
       "  'train_set_y': 'train_set_y|int64#1#209'},\n",
       " 'dims': {'test_set_x': [12288, 50],\n",
       "  'test_set_y': [1, 50],\n",
       "  'train_set_x': [12288, 209],\n",
       "  'train_set_y': [1, 209]},\n",
       " 'epoch': 0,\n",
       " 'epochs': 1,\n",
       " 'input_data': ['train_set_x', 'train_set_y', 'test_set_x', 'test_set_y'],\n",
       " 'layer': 2,\n",
       " 'layers': 2,\n",
       " 'learning_rate': 0.005,\n",
       " 'neurons': {'layer1': 3, 'layer2': 1},\n",
       " 'weight': 0.01}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = from_cache(endpoint=endpoint, key=\"parameters|json\")\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 209)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2 = from_cache(endpoint=endpoint, key=parameters['data_keys']['A2'])\n",
    "A2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current results output:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epoch0': {'cost': 0.6933895808784364}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = from_cache(endpoint=endpoint, key=parameters['data_keys']['results'])\n",
    "print(\"Current results output:\\n\")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "## Back Propogation\n",
    "### Trainer -> Neuron (Layer 2)\n",
    "** Sanity Check: Confirm that the derivative of the Cost Function (`dA2`) is initialized.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activations': {'layer1': 'relu', 'layer2': 'sigmoid'},\n",
       " 'bias': 0,\n",
       " 'data_keys': {'A1': 'A1|float64#3#209',\n",
       "  'A2': 'A2|float64#1#209',\n",
       "  'W1': 'W1|float64#3#12288',\n",
       "  'W2': 'W2|float64#1#3',\n",
       "  'b1': 'b1|float64#3#1',\n",
       "  'b2': 'b2|float64#1#1',\n",
       "  'dZ2': 'dZ2|float64#1#209',\n",
       "  'grads': 'grads|json',\n",
       "  'm': 'm|int',\n",
       "  'results': 'results|json',\n",
       "  'test_set_x': 'test_set_x|float64#12288#50',\n",
       "  'test_set_y': 'test_set_y|int64#1#50',\n",
       "  'train_set_x': 'train_set_x|float64#12288#209',\n",
       "  'train_set_y': 'train_set_y|int64#1#209'},\n",
       " 'dims': {'test_set_x': [12288, 50],\n",
       "  'test_set_y': [1, 50],\n",
       "  'train_set_x': [12288, 209],\n",
       "  'train_set_y': [1, 209]},\n",
       " 'epoch': 0,\n",
       " 'epochs': 1,\n",
       " 'input_data': ['train_set_x', 'train_set_y', 'test_set_x', 'test_set_y'],\n",
       " 'layer': 2,\n",
       " 'layers': 2,\n",
       " 'learning_rate': 0.005,\n",
       " 'neurons': {'layer1': 3, 'layer2': 1},\n",
       " 'weight': 0.01}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = from_cache(endpoint=endpoint, key=\"parameters|json\")\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** The derivative of the Cost is already built within the `TrainerLambda` and the event already sent to the `NeuronLambda`. Therefore the next step in the workflow is to process the derivatives for Layer 2 on the Neuron.\n",
    "\n",
    "---\n",
    "### Neuron (Layer 2) -> Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single RELU unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
    "    \n",
    "    # When z <= 0, you should set dz to 0 as well. \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single SIGMOID unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dZ2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 209)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the scene\n",
    "layer = 2\n",
    "ID = 1\n",
    "# get dZ2\n",
    "dz_name = 'dZ' + str(layer)\n",
    "print(dz_name)\n",
    "dz = from_cache(endpoint=endpoint,key=parameters['data_keys'][dz_name])\n",
    "dz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 209)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get activations for the previous layer\n",
    "a_name = 'A' + str(layer-1)\n",
    "A_prev = from_cache(\n",
    "    endpoint=endpoint,\n",
    "    key=parameters['data_keys'][a_name]\n",
    ")\n",
    "A_prev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** The shape is based on the previous layer's neuron size, so how to we handle this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_config=[784, 100, 100, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = len(layer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_layers-1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_config[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_layers-2, 0, -1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Hmmmmmm I think I'm working on the wrong layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
