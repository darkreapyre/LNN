{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L-Layer, Single Neuron Testing\n",
    "## Architecture\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"epochs\": 1,\n",
    "    \"layers\": 1,\n",
    "    \"activations\": {\n",
    "        \"layer1\": \"sigmoid\"\n",
    "    },\n",
    "    \"neurons\": {\n",
    "        \"layer1\": 1\n",
    "    },\n",
    "    \"weight\": 0,\n",
    "    \"bias\": 0,\n",
    "    \"learning_rate\": 0.005\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "## Forward Propogation\n",
    "### S3 Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ''\n",
    "# Simulate S3 event trigger data\n",
    "event = {\n",
    "    \"Records\": [\n",
    "        {\n",
    "            \"eventVersion\": \"2.0\",\n",
    "            \"eventTime\": \"1970-01-01T00:00:00.000Z\",\n",
    "            \"requestParameters\": {\n",
    "                \"sourceIPAddress\": \"127.0.0.1\"\n",
    "             },\n",
    "            \"s3\": {\n",
    "                \"configurationId\": \"testConfigRule\",\n",
    "                \"object\": {\n",
    "                    \"eTag\": \"0123456789abcdef0123456789abcdef\",\n",
    "                    \"sequencer\": \"0A1B2C3D4E5F678901\",\n",
    "                    \"key\": \"training_input/datasets.h5\",\n",
    "                    \"size\": 1024\n",
    "                },\n",
    "                \"bucket\": {\n",
    "                    \"arn\": \"arn:aws:s3:::lnn\",\n",
    "                    \"name\": \"lnn\",\n",
    "                    \"ownerIdentity\": {\n",
    "                        \"principalId\": \"EXAMPLE\"\n",
    "                    }\n",
    "                },\n",
    "                \"s3SchemaVersion\": \"1.0\"\n",
    "            },\n",
    "            \"responseElements\": {\n",
    "                \"x-amz-id-2\": \"EXAMPLE123/5678abcdefghijklambdaisawesome/mnopqrstuvwxyzABCDEFGH\",\n",
    "                \"x-amz-request-id\": \"EXAMPLE123456789\"\n",
    "            },\n",
    "            \"awsRegion\": \"us-west-2\",\n",
    "            \"eventName\": \"ObjectCreated:Put\",\n",
    "            \"userIdentity\": {\n",
    "                \"principalId\": \"EXAMPLE\"\n",
    "            },\n",
    "            \"eventSource\": \"aws:s3\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Neural Network Settings: \n",
      "\n",
      "{\n",
      "    \"activations\": {\n",
      "        \"layer1\": \"sigmoid\"\n",
      "    },\n",
      "    \"bias\": 0,\n",
      "    \"data_keys\": {\n",
      "        \"bias\": \"bias|int\",\n",
      "        \"grads\": \"grads|json\",\n",
      "        \"m\": \"m|int\",\n",
      "        \"results\": \"results|json\",\n",
      "        \"test_set_x\": \"test_set_x|float64#12288#50\",\n",
      "        \"test_set_y\": \"test_set_y|int64#1#50\",\n",
      "        \"train_set_x\": \"train_set_x|float64#12288#209\",\n",
      "        \"train_set_y\": \"train_set_y|int64#1#209\",\n",
      "        \"weights\": \"weights|float64#12288#1\"\n",
      "    },\n",
      "    \"dims\": {\n",
      "        \"test_set_x\": [\n",
      "            12288,\n",
      "            50\n",
      "        ],\n",
      "        \"test_set_y\": [\n",
      "            1,\n",
      "            50\n",
      "        ],\n",
      "        \"train_set_x\": [\n",
      "            12288,\n",
      "            209\n",
      "        ],\n",
      "        \"train_set_y\": [\n",
      "            1,\n",
      "            209\n",
      "        ]\n",
      "    },\n",
      "    \"epochs\": 1,\n",
      "    \"input_data\": [\n",
      "        \"train_set_x\",\n",
      "        \"train_set_y\",\n",
      "        \"test_set_x\",\n",
      "        \"test_set_y\"\n",
      "    ],\n",
      "    \"layers\": 1,\n",
      "    \"learning_rate\": 0.005,\n",
      "    \"neurons\": {\n",
      "        \"layer1\": 1\n",
      "    },\n",
      "    \"weight\": 0\n",
      "}\n",
      "Payload to be sent to TrainerLambda: \n",
      "{\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"start\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import launch\n",
    "from launch import *\n",
    "launch.lambda_handler(event, context)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Launch -> Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event = {\n",
    "    \"parameter_key\": \"parameters|json\",\n",
    "    \"state\": \"start\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Forward Propogation for epoch 0, layer 1\n",
      "Payload to be sent NeuronLambda: \n",
      "{\n",
      "    \"activation\": \"sigmoid\",\n",
      "    \"epoch\": 0,\n",
      "    \"id\": 1,\n",
      "    \"last\": \"True\",\n",
      "    \"layer\": 1,\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"forward\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import trainer\n",
    "from trainer import *\n",
    "trainer.lambda_handler(event, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "### Trainer -> Neuron (Layer 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload to be sent to TrainerLambda: \n",
      "{\n",
      "    \"epoch\": 0,\n",
      "    \"layer\": 2,\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"forward\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import neuron\n",
    "from neuron import *\n",
    "\n",
    "event = {\n",
    "    \"activation\": \"sigmoid\",\n",
    "    \"epoch\": 0,\n",
    "    \"id\": 1,\n",
    "    \"last\": \"True\",\n",
    "    \"layer\": 1,\n",
    "    \"parameter_key\": \"parameters|json\",\n",
    "    \"state\": \"forward\"\n",
    "}\n",
    "neuron.lambda_handler(event, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Neuron (Layer 1) -> Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.6931471805599453\n",
      "Starting Backward Propogation for epoch 0, layer 1\n",
      "Payload to be sent to NeuronLambda: \n",
      "{\n",
      "    \"activation\": \"sigmoid\",\n",
      "    \"epoch\": 0,\n",
      "    \"id\": 1,\n",
      "    \"last\": \"True\",\n",
      "    \"layer\": 1,\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"backward\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Event from NeuronLambda\n",
    "event = {\n",
    "    \"epoch\": 0,\n",
    "    \"layer\": 2,\n",
    "    \"parameter_key\": \"parameters|json\",\n",
    "    \"state\": \"forward\"\n",
    "}\n",
    "import trainer\n",
    "from trainer import *\n",
    "trainer.lambda_handler(event, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost\n",
    "The Cost shown above reflects the calculation done for L-Layer testing. The following is the intuition to verify that the Cost Funciton result:\n",
    "\n",
    "$$-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(a^{[L] (i)}\\right) + (1 - Y^{(i)}\\log\\left(1 - a^{[L](i)}\\right))$$\n",
    "\n",
    "Is the same as the Cost Function for a Single Neuron:\n",
    "\n",
    "$$-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} y^{(i)} \\log\\left(a^{(i)}\\right) + (1 - y^{(i)}) \\log\\left(1 - a^{(i)}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost for L-Layer: 0.69314718056\n",
      "Cost for Single Neuron: 0.69314718056\n"
     ]
    }
   ],
   "source": [
    "# Get the latest Parameters\n",
    "paramaters = from_cache(\n",
    "    endpoint=endpoint,\n",
    "    key='parameters|json'\n",
    ")\n",
    "# Get the training examples data\n",
    "A1 = from_cache(\n",
    "    endpoint=endpoint,\n",
    "    key=paramaters['data_keys']['A1']\n",
    ")\n",
    "Y = from_cache(\n",
    "    endpoint=endpoint,\n",
    "    key=parameters['data_keys']['train_set_y']\n",
    ")\n",
    "m = from_cache(\n",
    "    endpoint=endpoint,\n",
    "    key=parameters['data_keys']['m']\n",
    ")\n",
    "\n",
    "# Confirm that the data shapes match\n",
    "assert(Y.shape == (1, m))\n",
    "\n",
    "# Cost for L-Layer\n",
    "cost1 = -1/m * np.sum(np.multiply(Y, np.log(A1)) + np.multiply((1 - Y), np.log(1-A1)))\n",
    "print(\"Cost for L-Layer: \" + str(cost1))\n",
    "\n",
    "# Cost for Single NEuron\n",
    "cost2 = (-1 / m) * np.sum(Y * (np.log(A1)) + ((1 - Y) * np.log(1 - A1)))\n",
    "print(\"Cost for Single Neuron: \" + str(cost2))\n",
    "\n",
    "assert(cost1 == cost2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "## Back Propogation\n",
    "### Trainer -> Neuron (Layer 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload to be sent to TrainerLambda: \n",
      "{\n",
      "    \"epoch\": 0,\n",
      "    \"layer\": 0,\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"backward\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "event = {\n",
    "    \"activation\": \"sigmoid\",\n",
    "    \"epoch\": 0,\n",
    "    \"id\": 1,\n",
    "    \"last\": \"True\",\n",
    "    \"layer\": 1,\n",
    "    \"parameter_key\": \"parameters|json\",\n",
    "    \"state\": \"backward\"\n",
    "}\n",
    "import neuron\n",
    "from neuron import *\n",
    "neuron.lambda_handler(event, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check: Confirm the gradients were captured**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activations': {'layer1': 'sigmoid'},\n",
       " 'bias': 0,\n",
       " 'data_keys': {'A1': 'A1|float64#1#209',\n",
       "  'bias': 'bias|int',\n",
       "  'dZ1': 'dZ1|float64#1#209',\n",
       "  'grads': 'grads|json',\n",
       "  'm': 'm|int',\n",
       "  'results': 'results|json',\n",
       "  'test_set_x': 'test_set_x|float64#12288#50',\n",
       "  'test_set_y': 'test_set_y|int64#1#50',\n",
       "  'train_set_x': 'train_set_x|float64#12288#209',\n",
       "  'train_set_y': 'train_set_y|int64#1#209',\n",
       "  'weights': 'weights|float64#12288#1'},\n",
       " 'dims': {'test_set_x': [12288, 50],\n",
       "  'test_set_y': [1, 50],\n",
       "  'train_set_x': [12288, 209],\n",
       "  'train_set_y': [1, 209]},\n",
       " 'epoch': 0,\n",
       " 'epochs': 1,\n",
       " 'input_data': ['train_set_x', 'train_set_y', 'test_set_x', 'test_set_y'],\n",
       " 'layer': 0,\n",
       " 'layers': 1,\n",
       " 'learning_rate': 0.005,\n",
       " 'neurons': {'layer1': 1},\n",
       " 'weight': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = from_cache(\n",
    "    endpoint=endpoint,\n",
    "    key=\"parameters|json\"\n",
    ")\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer1': {'db': 'db|float64#0#0', 'dw': 'dw|float64#12288#1'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads = from_cache(\n",
    "    endpoint=endpoint,\n",
    "    key=parameters['data_keys']['grads']\n",
    ")\n",
    "grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Debug: Simulate `optimize()`, but now called `update_paramaters()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the derivatives from grads\n",
    "layer = 0\n",
    "dw = from_cache(\n",
    "    endpoint=endpoint,\n",
    "    key=grads['layer'+ str(layer + 1)]['dw']\n",
    ")\n",
    "db = from_cache(\n",
    "    endpoint=endpoint,\n",
    "    key=grads['layer'+ str(layer + 1)]['db']\n",
    ")\n",
    "\n",
    "# Retrieve initial weights, bias and learning rate\n",
    "w = from_cache(\n",
    "    endpoint=endpoint,\n",
    "    key=parameters['data_keys']['weights']\n",
    ")\n",
    "b = from_cache(\n",
    "    endpoint=endpoint,\n",
    "    key=parameters['data_keys']['bias']\n",
    ")\n",
    "learning_rate = parameters['learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated Weight: [[-0.00094418]\n",
      " [-0.00125997]\n",
      " [-0.00098471]\n",
      " ..., \n",
      " [-0.00101492]\n",
      " [-0.00124252]\n",
      " [-0.00064903]]\n",
      "updated Bias: -0.00311004784689\n"
     ]
    }
   ],
   "source": [
    "# Update parameters\n",
    "w = w - learning_rate * dw\n",
    "b = b - learning_rate * db\n",
    "print(\"updated Weight: \" + str(w))\n",
    "print(\"updated Bias: \" + str(b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
