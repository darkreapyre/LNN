{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L-Layer, Single Neuron Testing\n",
    "## Architecture\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"epochs\": 3,\n",
    "    \"layers\": 1,\n",
    "    \"activations\": {\n",
    "        \"layer1\": \"sigmoid\"\n",
    "    },\n",
    "    \"neurons\": {\n",
    "        \"layer1\": 1\n",
    "    },\n",
    "    \"weight\": 0,\n",
    "    \"bias\": 0,\n",
    "    \"learning_rate\": 0.005\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "## Forward Propogation\n",
    "### S3 Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ''\n",
    "# Simulate S3 event trigger data\n",
    "event = {\n",
    "    \"Records\": [\n",
    "        {\n",
    "            \"eventVersion\": \"2.0\",\n",
    "            \"eventTime\": \"1970-01-01T00:00:00.000Z\",\n",
    "            \"requestParameters\": {\n",
    "                \"sourceIPAddress\": \"127.0.0.1\"\n",
    "             },\n",
    "            \"s3\": {\n",
    "                \"configurationId\": \"testConfigRule\",\n",
    "                \"object\": {\n",
    "                    \"eTag\": \"0123456789abcdef0123456789abcdef\",\n",
    "                    \"sequencer\": \"0A1B2C3D4E5F678901\",\n",
    "                    \"key\": \"training_input/datasets.h5\",\n",
    "                    \"size\": 1024\n",
    "                },\n",
    "                \"bucket\": {\n",
    "                    \"arn\": \"arn:aws:s3:::lnn\",\n",
    "                    \"name\": \"lnn\",\n",
    "                    \"ownerIdentity\": {\n",
    "                        \"principalId\": \"EXAMPLE\"\n",
    "                    }\n",
    "                },\n",
    "                \"s3SchemaVersion\": \"1.0\"\n",
    "            },\n",
    "            \"responseElements\": {\n",
    "                \"x-amz-id-2\": \"EXAMPLE123/5678abcdefghijklambdaisawesome/mnopqrstuvwxyzABCDEFGH\",\n",
    "                \"x-amz-request-id\": \"EXAMPLE123456789\"\n",
    "            },\n",
    "            \"awsRegion\": \"us-west-2\",\n",
    "            \"eventName\": \"ObjectCreated:Put\",\n",
    "            \"userIdentity\": {\n",
    "                \"principalId\": \"EXAMPLE\"\n",
    "            },\n",
    "            \"eventSource\": \"aws:s3\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Neural Network Settings: \n",
      "\n",
      "{\n",
      "    \"activations\": {\n",
      "        \"layer1\": \"sigmoid\"\n",
      "    },\n",
      "    \"bias\": 0,\n",
      "    \"data_keys\": {\n",
      "        \"A0\": \"A0|float64#12288#209\",\n",
      "        \"Y\": \"Y|int64#1#209\",\n",
      "        \"bias\": \"bias|int\",\n",
      "        \"grads\": \"grads|json\",\n",
      "        \"m\": \"m|int\",\n",
      "        \"results\": \"results|json\",\n",
      "        \"test_set_x\": \"test_set_x|float64#12288#50\",\n",
      "        \"test_set_y\": \"test_set_y|int64#1#50\",\n",
      "        \"train_set_x\": \"train_set_x|float64#12288#209\",\n",
      "        \"train_set_y\": \"train_set_y|int64#1#209\",\n",
      "        \"weights\": \"weights|float64#12288#1\"\n",
      "    },\n",
      "    \"dims\": {\n",
      "        \"test_set_x\": [\n",
      "            12288,\n",
      "            50\n",
      "        ],\n",
      "        \"test_set_y\": [\n",
      "            1,\n",
      "            50\n",
      "        ],\n",
      "        \"train_set_x\": [\n",
      "            12288,\n",
      "            209\n",
      "        ],\n",
      "        \"train_set_y\": [\n",
      "            1,\n",
      "            209\n",
      "        ]\n",
      "    },\n",
      "    \"epochs\": 1,\n",
      "    \"input_data\": [\n",
      "        \"train_set_x\",\n",
      "        \"train_set_y\",\n",
      "        \"test_set_x\",\n",
      "        \"test_set_y\"\n",
      "    ],\n",
      "    \"layers\": 1,\n",
      "    \"learning_rate\": 0.005,\n",
      "    \"neurons\": {\n",
      "        \"layer1\": 1\n",
      "    },\n",
      "    \"s3_bucket\": \"lnn\",\n",
      "    \"weight\": 0\n",
      "}\n",
      "Payload to be sent to TrainerLambda: \n",
      "{\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"start\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import launch\n",
    "from launch import *\n",
    "launch.lambda_handler(event, context)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Launch -> Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event = {\n",
    "    \"parameter_key\": \"parameters|json\",\n",
    "    \"state\": \"start\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Forward Propogation for epoch 0, layer 1\n",
      "Payload to be sent NeuronLambda: \n",
      "{\n",
      "    \"activation\": \"sigmoid\",\n",
      "    \"epoch\": 0,\n",
      "    \"id\": 1,\n",
      "    \"last\": \"True\",\n",
      "    \"layer\": 1,\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"forward\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import trainer\n",
    "from trainer import *\n",
    "trainer.lambda_handler(event, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "### Trainer -> Neuron (Layer 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload to be sent to TrainerLambda: \n",
      "{\n",
      "    \"epoch\": 0,\n",
      "    \"layer\": 2,\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"forward\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import neuron\n",
    "from neuron import *\n",
    "\n",
    "event = {\n",
    "    \"activation\": \"sigmoid\",\n",
    "    \"epoch\": 0,\n",
    "    \"id\": 1,\n",
    "    \"last\": \"True\",\n",
    "    \"layer\": 1,\n",
    "    \"parameter_key\": \"parameters|json\",\n",
    "    \"state\": \"forward\"\n",
    "}\n",
    "neuron.lambda_handler(event, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Neuron (Layer 1) -> Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.6931471805599453\n",
      "Starting Backward Propogation for epoch 0, layer 1\n",
      "Payload to be sent to NeuronLambda: \n",
      "{\n",
      "    \"activation\": \"sigmoid\",\n",
      "    \"epoch\": 0,\n",
      "    \"id\": 1,\n",
      "    \"last\": \"True\",\n",
      "    \"layer\": 1,\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"backward\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Event from NeuronLambda\n",
    "event = {\n",
    "    \"epoch\": 0,\n",
    "    \"layer\": 2,\n",
    "    \"parameter_key\": \"parameters|json\",\n",
    "    \"state\": \"forward\"\n",
    "}\n",
    "import trainer\n",
    "from trainer import *\n",
    "trainer.lambda_handler(event, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost\n",
    "The Cost shown above reflects the calculation done for L-Layer testing. The following is the intuition to verify that the Cost Funciton result:\n",
    "\n",
    "$$-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(a^{[L] (i)}\\right) + (1 - Y^{(i)}\\log\\left(1 - a^{[L](i)}\\right))$$\n",
    "\n",
    "Is the same as the Cost Function for a Single Neuron:\n",
    "\n",
    "$$-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} y^{(i)} \\log\\left(a^{(i)}\\right) + (1 - y^{(i)}) \\log\\left(1 - a^{(i)}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost for L-Layer: 0.69314718056\n",
      "Cost for Single Neuron: 0.69314718056\n"
     ]
    }
   ],
   "source": [
    "# Get the latest Parameters\n",
    "paramaters = from_cache(\n",
    "    endpoint=endpoint,\n",
    "    key='parameters|json'\n",
    ")\n",
    "# Get the training examples data\n",
    "A1 = from_cache(\n",
    "    endpoint=endpoint,\n",
    "    key=paramaters['data_keys']['A1']\n",
    ")\n",
    "Y = from_cache(\n",
    "    endpoint=endpoint,\n",
    "    key=parameters['data_keys']['train_set_y']\n",
    ")\n",
    "m = from_cache(\n",
    "    endpoint=endpoint,\n",
    "    key=parameters['data_keys']['m']\n",
    ")\n",
    "\n",
    "# Confirm that the data shapes match\n",
    "assert(Y.shape == (1, m))\n",
    "\n",
    "# Cost for L-Layer\n",
    "cost1 = -1/m * np.sum(np.multiply(Y, np.log(A1)) + np.multiply((1 - Y), np.log(1-A1)))\n",
    "print(\"Cost for L-Layer: \" + str(cost1))\n",
    "\n",
    "# Cost for Single NEuron\n",
    "cost2 = (-1 / m) * np.sum(Y * (np.log(A1)) + ((1 - Y) * np.log(1 - A1)))\n",
    "print(\"Cost for Single Neuron: \" + str(cost2))\n",
    "\n",
    "assert(cost1 == cost2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "## Back Propogation\n",
    "### Trainer -> Neuron (Layer 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload to be sent to TrainerLambda: \n",
      "{\n",
      "    \"epoch\": 0,\n",
      "    \"layer\": 0,\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"backward\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "event = {\n",
    "    \"activation\": \"sigmoid\",\n",
    "    \"epoch\": 0,\n",
    "    \"id\": 1,\n",
    "    \"last\": \"True\",\n",
    "    \"layer\": 1,\n",
    "    \"parameter_key\": \"parameters|json\",\n",
    "    \"state\": \"backward\"\n",
    "}\n",
    "import neuron\n",
    "from neuron import *\n",
    "neuron.lambda_handler(event, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check: Confirm the gradients were captured**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activations': {'layer1': 'sigmoid'},\n",
       " 'bias': 0,\n",
       " 'data_keys': {'A0': 'A0|float64#12288#209',\n",
       "  'A1': 'A1|float64#1#209',\n",
       "  'Y': 'Y|int64#1#209',\n",
       "  'bias': 'bias|int',\n",
       "  'dZ1': 'dZ1|float64#1#209',\n",
       "  'grads': 'grads|json',\n",
       "  'm': 'm|int',\n",
       "  'results': 'results|json',\n",
       "  'test_set_x': 'test_set_x|float64#12288#50',\n",
       "  'test_set_y': 'test_set_y|int64#1#50',\n",
       "  'train_set_x': 'train_set_x|float64#12288#209',\n",
       "  'train_set_y': 'train_set_y|int64#1#209',\n",
       "  'weights': 'weights|float64#12288#1'},\n",
       " 'dims': {'test_set_x': [12288, 50],\n",
       "  'test_set_y': [1, 50],\n",
       "  'train_set_x': [12288, 209],\n",
       "  'train_set_y': [1, 209]},\n",
       " 'epoch': 0,\n",
       " 'epochs': 1,\n",
       " 'input_data': ['train_set_x', 'train_set_y', 'test_set_x', 'test_set_y'],\n",
       " 'layer': 0,\n",
       " 'layers': 1,\n",
       " 'learning_rate': 0.005,\n",
       " 'neurons': {'layer1': 1},\n",
       " 's3_bucket': 'lnn',\n",
       " 'weight': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = from_cache(\n",
    "    endpoint=endpoint,\n",
    "    key=\"parameters|json\"\n",
    ")\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer1': {'db': 'db|float64#0#0', 'dw': 'dw|float64#12288#1'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads = from_cache(\n",
    "    endpoint=endpoint,\n",
    "    key=parameters['data_keys']['grads']\n",
    ")\n",
    "grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuron (Layer 1) -> Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Completed Successfully!\n"
     ]
    }
   ],
   "source": [
    "event = {\n",
    "    \"epoch\": 0,\n",
    "    \"layer\": 0,\n",
    "    \"parameter_key\": \"parameters|json\",\n",
    "    \"state\": \"backward\"\n",
    "}\n",
    "import trainer\n",
    "from trainer import *\n",
    "trainer.lambda_handler(event, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# s32numpy function\n",
    "def s3numpy(bucket, key):\n",
    "    \"\"\"\n",
    "    Retrieves a saved numpy array from S3 without using a local copy\n",
    "    \n",
    "    Arguments:\n",
    "    bucket -- Name of the S3 Bucket where the array is stored\n",
    "    key -- name of the saved numpy file. Must be in a string format\n",
    "    \n",
    "    Returns:\n",
    "    array -- Numpy array\n",
    "    \"\"\"\n",
    "    file = io.BytesIO(\n",
    "        s3_client.get_object(\n",
    "            Bucket=bucket,\n",
    "            Key='predict_input/'+key)['Body'].read()\n",
    "    )\n",
    "    content = file.getvalue()\n",
    "    array = np.load(io.BytesIO(content))\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12288, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket = parameters['s3_bucket']\n",
    "file = 'weights'\n",
    "s3numpy(bucket, file).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(-0.003110047846889952)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'bias'\n",
    "s3numpy(bucket, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch0': {'cost': 0.6931471805599453}}\n"
     ]
    }
   ],
   "source": [
    "content = s3_resource.Object(bucket, 'training_results/results.json')\n",
    "file = content.get()['Body'].read().decode('utf-8')\n",
    "json_content = json.loads(file)\n",
    "print(json_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Prediction Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediciton funciton\n",
    "def predict(w, b, X):\n",
    "    \"\"\"\n",
    "    Predict wether the label is 1 or 0 (cat vs. non-cat)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights from trained model on S3, (num_px * num_px, 3, 1)\n",
    "    b -- scalar representing the bias from trained model from S3\n",
    "    X -- Input data (num_px * num_px * 3, no. examples)\n",
    "    \n",
    "    Returns:\n",
    "    Y -- Numpy array containing predeictions of 1 or 0\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_pred = np.zeros((1, m))\n",
    "    \n",
    "    # Compute the vector `A` predicting the probabilities of a cat\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    \n",
    "    # Convert probabilities to predictions\n",
    "    for i in range(A.shape[1]):\n",
    "        if A[0, i] > 0.5:\n",
    "            Y_pred[0, i] = 1\n",
    "        else:\n",
    "            Y_pred[0, i] = 0\n",
    "    assert(Y_pred.shape == (1, m))\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "X_test = from_cache(endpoint=endpoint, key=parameters['data_keys']['test_set_x'])\n",
    "Y_test = from_cache(endpoint=endpoint, key=parameters['data_keys']['test_set_y'])\n",
    "X_train = from_cache(endpoint=endpoint, key=parameters['data_keys']['train_set_x'])\n",
    "Y_train = from_cache(endpoint=endpoint, key=parameters['data_keys']['train_set_y'])\n",
    "w = s3numpy(bucket, 'weights')\n",
    "b = s3numpy(bucket, 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prediciton test\n",
    "Y_prediction_test = predict(w, b, X_test)\n",
    "Y_prediction_train = predict(w, b, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the Training Set: 99.6555023923445\n",
      "Accuracy on the Test Set: 99.34\n"
     ]
    }
   ],
   "source": [
    "# Train/Terst Error\n",
    "print(\"Accuracy on the Training Set: {}\".format(\n",
    "    100 - np.mean(np.abs(Y_prediction_train - Y_train)))\n",
    ")\n",
    "print(\"Accuracy on the Test Set: {}\".format(\n",
    "    100 - np.mean(np.abs(Y_prediction_test - Y_test)))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** There is signifiant over fitting because only one epoch was run.\n",
    "\n",
    "---\n",
    "## Prediction Service"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
