{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L-Layer Testing\n",
    "## Architecture\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"epochs\": 1,\n",
    "    \"layers\": 2,\n",
    "    \"activations\": {\n",
    "        \"layer1\": \"sigmoid\",\n",
    "        \"layer2\": \"relu\"\n",
    "    },\n",
    "    \"neurons\": {\n",
    "        \"layer1\": 3,\n",
    "        \"layer2\": 1\n",
    "    },\n",
    "    \"weight\": 0.01,\n",
    "    \"bias\": 0,\n",
    "    \"learning_rate\": 0.005\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "## Forward Propogation\n",
    "### S3 Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ''\n",
    "# Simulate S3 event trigger data\n",
    "event = {\n",
    "    \"Records\": [\n",
    "        {\n",
    "            \"eventVersion\": \"2.0\",\n",
    "            \"eventTime\": \"1970-01-01T00:00:00.000Z\",\n",
    "            \"requestParameters\": {\n",
    "                \"sourceIPAddress\": \"127.0.0.1\"\n",
    "             },\n",
    "            \"s3\": {\n",
    "                \"configurationId\": \"testConfigRule\",\n",
    "                \"object\": {\n",
    "                    \"eTag\": \"0123456789abcdef0123456789abcdef\",\n",
    "                    \"sequencer\": \"0A1B2C3D4E5F678901\",\n",
    "                    \"key\": \"training_input/datasets.h5\",\n",
    "                    \"size\": 1024\n",
    "                },\n",
    "                \"bucket\": {\n",
    "                    \"arn\": \"arn:aws:s3:::lnn\",\n",
    "                    \"name\": \"lnn\",\n",
    "                    \"ownerIdentity\": {\n",
    "                        \"principalId\": \"EXAMPLE\"\n",
    "                    }\n",
    "                },\n",
    "                \"s3SchemaVersion\": \"1.0\"\n",
    "            },\n",
    "            \"responseElements\": {\n",
    "                \"x-amz-id-2\": \"EXAMPLE123/5678abcdefghijklambdaisawesome/mnopqrstuvwxyzABCDEFGH\",\n",
    "                \"x-amz-request-id\": \"EXAMPLE123456789\"\n",
    "            },\n",
    "            \"awsRegion\": \"us-west-2\",\n",
    "            \"eventName\": \"ObjectCreated:Put\",\n",
    "            \"userIdentity\": {\n",
    "                \"principalId\": \"EXAMPLE\"\n",
    "            },\n",
    "            \"eventSource\": \"aws:s3\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Neural Network Settings: \n",
      "\n",
      "{\n",
      "    \"activations\": {\n",
      "        \"layer1\": \"relu\",\n",
      "        \"layer2\": \"sigmoid\"\n",
      "    },\n",
      "    \"bias\": 0,\n",
      "    \"data_keys\": {\n",
      "        \"W1\": \"W1|float64#3#12288\",\n",
      "        \"W2\": \"W2|float64#1#3\",\n",
      "        \"b1\": \"b1|float64#3#1\",\n",
      "        \"b2\": \"b2|float64#1#1\",\n",
      "        \"results\": \"results|json\",\n",
      "        \"test_set_x\": \"test_set_x|float64#12288#50\",\n",
      "        \"test_set_y\": \"test_set_y|int64#1#50\",\n",
      "        \"train_set_x\": \"train_set_x|float64#12288#209\",\n",
      "        \"train_set_y\": \"train_set_y|int64#1#209\"\n",
      "    },\n",
      "    \"dims\": {\n",
      "        \"test_set_x\": [\n",
      "            12288,\n",
      "            50\n",
      "        ],\n",
      "        \"test_set_y\": [\n",
      "            1,\n",
      "            50\n",
      "        ],\n",
      "        \"train_set_x\": [\n",
      "            12288,\n",
      "            209\n",
      "        ],\n",
      "        \"train_set_y\": [\n",
      "            1,\n",
      "            209\n",
      "        ]\n",
      "    },\n",
      "    \"epochs\": 1,\n",
      "    \"input_data\": [\n",
      "        \"train_set_x\",\n",
      "        \"train_set_y\",\n",
      "        \"test_set_x\",\n",
      "        \"test_set_y\"\n",
      "    ],\n",
      "    \"layers\": 2,\n",
      "    \"learning_rate\": 0.005,\n",
      "    \"neurons\": {\n",
      "        \"layer1\": 3,\n",
      "        \"layer2\": 1\n",
      "    },\n",
      "    \"weight\": 0.01\n",
      "}\n",
      "Payload to be sent to TrainerLambda: \n",
      "{\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"start\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import launch\n",
    "from launch import *\n",
    "launch.lambda_handler(event, context)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Launch -> Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event = {\n",
    "    \"parameter_key\": \"parameters|json\",\n",
    "    \"state\": \"start\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Forward Propogation for epoch 0, layer 1\n",
      "Payload to be sent NeuronLambda: \n",
      "{\n",
      "    \"activation\": \"relu\",\n",
      "    \"epoch\": 0,\n",
      "    \"id\": 1,\n",
      "    \"last\": \"False\",\n",
      "    \"layer\": 1,\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"forward\"\n",
      "}\n",
      "Payload to be sent NeuronLambda: \n",
      "{\n",
      "    \"activation\": \"relu\",\n",
      "    \"epoch\": 0,\n",
      "    \"id\": 2,\n",
      "    \"last\": \"False\",\n",
      "    \"layer\": 1,\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"forward\"\n",
      "}\n",
      "Payload to be sent NeuronLambda: \n",
      "{\n",
      "    \"activation\": \"relu\",\n",
      "    \"epoch\": 0,\n",
      "    \"id\": 3,\n",
      "    \"last\": \"True\",\n",
      "    \"layer\": 1,\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"forward\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import trainer\n",
    "from trainer import *\n",
    "trainer.lambda_handler(event, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "### Trainer -> Neuron (Layer 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import neuron\n",
    "from neuron import *\n",
    "\n",
    "event = {\n",
    "    \"1\": {\n",
    "        \"activation\": \"relu\",\n",
    "        \"epoch\": 0,\n",
    "        \"id\": 1,\n",
    "        \"last\": \"False\",\n",
    "        \"layer\": 1,\n",
    "        \"parameter_key\": \"parameters|json\",\n",
    "        \"state\": \"forward\"\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"activation\": \"relu\",\n",
    "        \"epoch\": 0,\n",
    "        \"id\": 2,\n",
    "        \"last\": \"False\",\n",
    "        \"layer\": 1,\n",
    "        \"parameter_key\": \"parameters|json\",\n",
    "        \"state\": \"forward\"\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"activation\": \"relu\",\n",
    "        \"epoch\": 0,\n",
    "        \"id\": 3,\n",
    "        \"last\": \"True\",\n",
    "        \"layer\": 1,\n",
    "        \"parameter_key\": \"parameters|json\",\n",
    "        \"state\": \"forward\"\n",
    "    }\n",
    "}\n",
    "event = dumps(event)\n",
    "event = loads(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "layer = 3\n",
    "parameters = from_cache(endpoint=endpoint, key=\"parameters|json\")\n",
    "if layer == parameters['layers'] + 1:\n",
    "    print(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activations': {'layer1': 'relu', 'layer2': 'sigmoid'},\n",
       " 'bias': 0,\n",
       " 'data_keys': {'W1': 'W1|float64#3#12288',\n",
       "  'W2': 'W2|float64#1#3',\n",
       "  'b1': 'b1|float64#3#1',\n",
       "  'b2': 'b2|float64#1#1',\n",
       "  'results': 'results|json',\n",
       "  'test_set_x': 'test_set_x|float64#12288#50',\n",
       "  'test_set_y': 'test_set_y|int64#1#50',\n",
       "  'train_set_x': 'train_set_x|float64#12288#209',\n",
       "  'train_set_y': 'train_set_y|int64#1#209'},\n",
       " 'dims': {'test_set_x': [12288, 50],\n",
       "  'test_set_y': [1, 50],\n",
       "  'train_set_x': [12288, 209],\n",
       "  'train_set_y': [1, 209]},\n",
       " 'epoch': 0,\n",
       " 'epochs': 1,\n",
       " 'input_data': ['train_set_x', 'train_set_y', 'test_set_x', 'test_set_y'],\n",
       " 'layer': 1,\n",
       " 'layers': 2,\n",
       " 'learning_rate': 0.005,\n",
       " 'neurons': {'layer1': 3, 'layer2': 1},\n",
       " 'weight': 0.01}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_key = event.get('1')['parameter_key']\n",
    "parameters = from_cache(endpoint=endpoint, key=parameter_key)\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Layer: 1\n",
      "Neuron 1 event:\n",
      "{\"activation\": \"relu\", \"epoch\": 0, \"id\": 1, \"last\": \"False\", \"layer\": 1, \"parameter_key\": \"parameters|json\", \"state\": \"forward\"}\n",
      "Neuron 2 event:\n",
      "{\"activation\": \"relu\", \"epoch\": 0, \"id\": 2, \"last\": \"False\", \"layer\": 1, \"parameter_key\": \"parameters|json\", \"state\": \"forward\"}\n",
      "Payload to be sent to TrainerLambda: \n",
      "{\n",
      "    \"epoch\": 0,\n",
      "    \"layer\": 2,\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"forward\"\n",
      "}\n",
      "Neuron 3 event:\n",
      "{\"activation\": \"relu\", \"epoch\": 0, \"id\": 3, \"last\": \"True\", \"layer\": 1, \"parameter_key\": \"parameters|json\", \"state\": \"forward\"}\n"
     ]
    }
   ],
   "source": [
    "layer = event.get('1')['layer']\n",
    "print(\"Processing Layer: \" + str(layer))\n",
    "event1 = event.get('1')\n",
    "print(\"Neuron 1 event:\\n\" + dumps(event1))\n",
    "neuron.lambda_handler(event=event1, context='')\n",
    "event2 = event.get('2')\n",
    "print(\"Neuron 2 event:\\n\" + dumps(event2))\n",
    "neuron.lambda_handler(event=event2, context='')\n",
    "event3 = event.get('3')\n",
    "neuron.lambda_handler(event=event3, context='')\n",
    "print(\"Neuron 3 event:\\n\" + dumps(event3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Neuron (Layer 1) -> Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Propogating forward onto Layer 2\n",
      "Starting Forward Propogation for epoch 0, layer 2\n",
      "Payload to be sent NeuronLambda: \n",
      "{\n",
      "    \"activation\": \"sigmoid\",\n",
      "    \"epoch\": 0,\n",
      "    \"id\": 1,\n",
      "    \"last\": \"True\",\n",
      "    \"layer\": 2,\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"forward\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import trainer\n",
    "from trainer import *\n",
    "event = {\n",
    "    \"epoch\": 0,\n",
    "    \"layer\": 2,\n",
    "    \"parameter_key\": \"parameters|json\",\n",
    "    \"state\": \"forward\"\n",
    "}\n",
    "trainer.lambda_handler(event, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check: Confirm that `TrainerLambda` processed Layer 1 Activations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activations': {'layer1': 'relu', 'layer2': 'sigmoid'},\n",
       " 'bias': 0,\n",
       " 'data_keys': {'A1': 'A1|float64#3#209',\n",
       "  'W1': 'W1|float64#3#12288',\n",
       "  'W2': 'W2|float64#1#3',\n",
       "  'b1': 'b1|float64#3#1',\n",
       "  'b2': 'b2|float64#1#1',\n",
       "  'results': 'results|json',\n",
       "  'test_set_x': 'test_set_x|float64#12288#50',\n",
       "  'test_set_y': 'test_set_y|int64#1#50',\n",
       "  'train_set_x': 'train_set_x|float64#12288#209',\n",
       "  'train_set_y': 'train_set_y|int64#1#209'},\n",
       " 'dims': {'test_set_x': [12288, 50],\n",
       "  'test_set_y': [1, 50],\n",
       "  'train_set_x': [12288, 209],\n",
       "  'train_set_y': [1, 209]},\n",
       " 'epoch': 0,\n",
       " 'epochs': 1,\n",
       " 'input_data': ['train_set_x', 'train_set_y', 'test_set_x', 'test_set_y'],\n",
       " 'layer': 2,\n",
       " 'layers': 2,\n",
       " 'learning_rate': 0.005,\n",
       " 'neurons': {'layer1': 3, 'layer2': 1},\n",
       " 'weight': 0.01}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = from_cache(endpoint=endpoint, key='parameters|json')\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 209)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1 = from_cache(endpoint=endpoint, key=parameters['data_keys']['A1'])\n",
    "A1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "### Trainer -> Neuron (Layer 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload to be sent to TrainerLambda: \n",
      "{\n",
      "    \"epoch\": 0,\n",
      "    \"layer\": 3,\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"forward\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import neuron\n",
    "from neuron import *\n",
    "event = {\n",
    "    \"activation\": \"sigmoid\",\n",
    "    \"epoch\": 0,\n",
    "    \"id\": 1,\n",
    "    \"last\": \"True\",\n",
    "    \"layer\": 2,\n",
    "    \"parameter_key\": \"parameters|json\",\n",
    "    \"state\": \"forward\"\n",
    "}\n",
    "neuron.lambda_handler(event, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "### Neuron (Layer 2) -> Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.6931378502927884\n",
      "Starting Backward Propogation for epoch 0, layer 2\n",
      "Payload to be sent to NeuronLambda: \n",
      "{\n",
      "    \"activastion\": \"sigmoid\",\n",
      "    \"epoch\": 0,\n",
      "    \"id\": 1,\n",
      "    \"last\": \"True\",\n",
      "    \"layer\": 2,\n",
      "    \"parameter_key\": \"parameters|json\",\n",
      "    \"state\": \"backward\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import trainer\n",
    "from trainer import *\n",
    "event = {\n",
    "    \"epoch\": 0,\n",
    "    \"layer\": 3,\n",
    "    \"parameter_key\": \"parameters|json\",\n",
    "    \"state\": \"forward\"\n",
    "}\n",
    "trainer.lambda_handler(event, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check: Confirm `results` have been updated with the correct cost.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activations': {'layer1': 'relu', 'layer2': 'sigmoid'},\n",
       " 'bias': 0,\n",
       " 'data_keys': {'A1': 'A1|float64#3#209',\n",
       "  'A2': 'A2|float64#1#209',\n",
       "  'W1': 'W1|float64#3#12288',\n",
       "  'W2': 'W2|float64#1#3',\n",
       "  'b1': 'b1|float64#3#1',\n",
       "  'b2': 'b2|float64#1#1',\n",
       "  'dA2': 'dA2|float64#1#209',\n",
       "  'results': 'results|json',\n",
       "  'test_set_x': 'test_set_x|float64#12288#50',\n",
       "  'test_set_y': 'test_set_y|int64#1#50',\n",
       "  'train_set_x': 'train_set_x|float64#12288#209',\n",
       "  'train_set_y': 'train_set_y|int64#1#209'},\n",
       " 'dims': {'test_set_x': [12288, 50],\n",
       "  'test_set_y': [1, 50],\n",
       "  'train_set_x': [12288, 209],\n",
       "  'train_set_y': [1, 209]},\n",
       " 'epoch': 0,\n",
       " 'epochs': 1,\n",
       " 'input_data': ['train_set_x', 'train_set_y', 'test_set_x', 'test_set_y'],\n",
       " 'layer': 2,\n",
       " 'layers': 2,\n",
       " 'learning_rate': 0.005,\n",
       " 'neurons': {'layer1': 3, 'layer2': 1},\n",
       " 'weight': 0.01}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = from_cache(endpoint=endpoint, key=\"parameters|json\")\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 209)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2 = from_cache(endpoint=endpoint, key=parameters['data_keys']['A2'])\n",
    "A2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current results output:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epoch0': {'cost': 0.6931378502927884}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = from_cache(endpoint=endpoint, key=parameters['data_keys']['results'])\n",
    "print(\"Current results output:\\n\")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "## Back Propogation\n",
    "### Trainer -> Neuron (Layer 2)\n",
    "** Sanity Check: Confirm that the derivative of the Cost Function (`dA2`) is initialized.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activations': {'layer1': 'relu', 'layer2': 'sigmoid'},\n",
       " 'bias': 0,\n",
       " 'data_keys': {'A1': 'A1|float64#3#209',\n",
       "  'A2': 'A2|float64#1#209',\n",
       "  'W1': 'W1|float64#3#12288',\n",
       "  'W2': 'W2|float64#1#3',\n",
       "  'b1': 'b1|float64#3#1',\n",
       "  'b2': 'b2|float64#1#1',\n",
       "  'dA2': 'dA2|float64#1#209',\n",
       "  'results': 'results|json',\n",
       "  'test_set_x': 'test_set_x|float64#12288#50',\n",
       "  'test_set_y': 'test_set_y|int64#1#50',\n",
       "  'train_set_x': 'train_set_x|float64#12288#209',\n",
       "  'train_set_y': 'train_set_y|int64#1#209'},\n",
       " 'dims': {'test_set_x': [12288, 50],\n",
       "  'test_set_y': [1, 50],\n",
       "  'train_set_x': [12288, 209],\n",
       "  'train_set_y': [1, 209]},\n",
       " 'epoch': 0,\n",
       " 'epochs': 1,\n",
       " 'input_data': ['train_set_x', 'train_set_y', 'test_set_x', 'test_set_y'],\n",
       " 'layer': 2,\n",
       " 'layers': 2,\n",
       " 'learning_rate': 0.005,\n",
       " 'neurons': {'layer1': 3, 'layer2': 1},\n",
       " 'weight': 0.01}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = from_cache(endpoint=endpoint, key=\"parameters|json\")\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** The derivative of the Cost is already built within the `TrainerLambda` and the event already sent to the `NeuronLambda`. Therefore the next step in the workflow is to process the derivatives for Layer 2 on the Neuron.\n",
    "\n",
    "---\n",
    "### Neuron (Layer 2) -> Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import neuron\n",
    "from neuron import *\n",
    "event = {\n",
    "    \"activation\": \"sigmoid\",\n",
    "    \"epoch\": 0,\n",
    "    \"id\": 1,\n",
    "    \"last\": \"True\",\n",
    "    \"layer\": 2,\n",
    "    \"parameter_key\": \"parameters|json\",\n",
    "    \"state\": \"backward\"\n",
    "}\n",
    "#neuron.lambda_handler(event, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single RELU unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
    "    \n",
    "    # When z <= 0, you should set dz to 0 as well. \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single SIGMOID unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "da shape: (1, 209)\n",
      "a shape: (1, 209)\n"
     ]
    }
   ],
   "source": [
    "layer = 2\n",
    "ID = 1\n",
    "if layer == parameters['layers']:\n",
    "    da = from_cache(\n",
    "        endpoint=endpoint,\n",
    "        key=parameters['data_keys']['dA'+str(layer)])[ID-1, :].reshape(\n",
    "            1,\n",
    "            parameters['dims']['train_set_y'][1]\n",
    "        )\n",
    "    a = from_cache(\n",
    "        endpoint=endpoint,\n",
    "        key=parameters['data_keys']['A'+str(layer)])[ID-1, :].reshape(\n",
    "            1,\n",
    "            parameters['dims']['train_set_y'][1]\n",
    "        )\n",
    "print(\"da shape: \" + str(da.shape))\n",
    "print(\"a shape: \" + str(a.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Do I need to hard code the shape? If so, does it need to be based on the layer OR does that `if` statment happen for `A0`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 209)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = 2\n",
    "ID = 1\n",
    "da = from_cache(\n",
    "    endpoint=endpoint,\n",
    "    key=parameters['data_keys']['dA'+str(layer)]\n",
    ")\n",
    "da.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** After further thought, the Neuron needs to be idempotent to potential multi-classification or CovNet etc., so I need to hard code the shape because if I don't then the shape will be `(209,)`. But do I still need to hard code this to the last layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 209)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = 2\n",
    "ID = 1\n",
    "da = from_cache(\n",
    "    endpoint=endpoint,\n",
    "    key=parameters['data_keys']['dA'+str(layer)])[ID-1, :].reshape(\n",
    "        parameters['neurons']['layer'+str(layer)],\n",
    "        parameters['dims']['train_set_y'][1]\n",
    ")\n",
    "da.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 209)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = from_cache(\n",
    "    endpoint=endpoint,\n",
    "    key=parameters['data_keys']['A'+str(layer)])[ID-1, :].reshape(\n",
    "        parameters['neurons']['layer'+str(layer)],\n",
    "        parameters['dims']['train_set_y'][1]\n",
    ")\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation: sigmoid\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 209)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Derivative of the non-linear activation\n",
    "activation = event.get('activation')\n",
    "print(\"activation: \" + activation)\n",
    "if activation == \"sigmoid\":\n",
    "    dz = sigmoid_backward(da, a)\n",
    "elif activation == \"relu\":\n",
    "    dz = relu_backward(da, a)\n",
    "else:\n",
    "    print(\"Backward Activation function not yet iplemented\")\n",
    "dz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.00044257,  2.00052776, -2.        ,  1.99955604,  2.00081408,\n",
       "         2.00090029,  1.99964713, -2.        ,  2.        ,  2.        ,\n",
       "         2.        , -2.00013402,  2.        , -2.00044353, -1.99981028,\n",
       "         2.00036471,  2.00045343,  2.00089246,  2.        , -2.00011096,\n",
       "         2.        ,  1.99978175,  1.99999013,  2.00025545, -2.00064185,\n",
       "        -2.00040766,  1.99914226, -2.00091657,  1.99976457, -1.99947795,\n",
       "         2.00004083,  2.        ,  2.00016709,  2.        ,  1.99940015,\n",
       "         2.        ,  1.99962628,  2.        , -2.00023868,  2.        ,\n",
       "         2.00013184, -2.00069642, -1.99989408,  2.00010593,  2.        ,\n",
       "         2.0006029 ,  2.00056452, -1.99987177,  1.99932981,  2.        ,\n",
       "        -2.        ,  2.        ,  2.        ,  2.        , -1.99963586,\n",
       "         2.00027624, -2.        , -2.        ,  2.00002596, -2.00008488,\n",
       "        -2.        , -2.        ,  2.        ,  1.99857634,  2.        ,\n",
       "         1.99982322,  2.        ,  2.        , -1.99969403,  2.        ,\n",
       "         2.        , -2.00017699,  1.99946972,  2.        ,  2.        ,\n",
       "         2.        ,  2.        ,  2.        ,  1.9995274 ,  1.99939433,\n",
       "         1.99915744,  1.99984378,  2.        , -2.        , -2.        ,\n",
       "         2.0008789 ,  2.        ,  2.00048686, -1.99996187,  2.00090387,\n",
       "         2.00010014,  2.        , -2.00070492, -2.        , -1.99995854,\n",
       "         2.        ,  2.000232  , -2.00097375,  2.        ,  2.        ,\n",
       "         2.        ,  1.99876756, -2.00010671,  2.00043705, -1.99974913,\n",
       "         2.        , -2.        , -2.        , -2.00024765, -2.        ,\n",
       "        -2.00082105, -2.00022388,  1.99930405,  1.99982134,  1.99972474,\n",
       "         1.9990276 ,  2.00018697, -2.        ,  2.        ,  2.00002495,\n",
       "         2.        , -2.        ,  2.        ,  2.        , -2.        ,\n",
       "         2.        , -2.00003251,  2.00050685, -2.00114949, -2.        ,\n",
       "         2.        ,  1.9994126 ,  2.        , -1.9997495 , -2.        ,\n",
       "        -2.        , -2.00019667, -2.00008474,  2.00008919,  2.        ,\n",
       "         1.99955678,  2.        , -2.00042496,  2.        , -2.00003884,\n",
       "        -1.99999107, -1.99934904,  2.        , -2.0005446 , -2.        ,\n",
       "         1.99984369,  1.99960626,  1.99965969, -1.99969764,  1.99989258,\n",
       "         2.00006289, -2.        ,  2.        ,  2.00081334,  2.        ,\n",
       "         1.99917568,  2.00097874, -1.99988967,  2.        , -1.99910252,\n",
       "         1.99991036, -2.        ,  2.        ,  2.        , -1.99919524,\n",
       "        -2.        , -2.        ,  2.        ,  2.        , -2.        ,\n",
       "        -1.99945393,  2.        , -2.        ,  1.9995742 , -1.99979426,\n",
       "         2.00074181,  2.        ,  2.00044215,  2.        ,  2.        ,\n",
       "        -2.        ,  1.99971264,  1.99971956, -1.99973662,  2.        ,\n",
       "         1.99992056,  2.00029735, -1.99917933,  2.        ,  1.99967431,\n",
       "         2.        ,  1.99951787, -2.        ,  1.99842749,  1.99954157,\n",
       "        -1.99938618,  2.00002173,  2.        ,  2.00014336,  1.99937449,\n",
       "         1.99906649,  2.0001779 ,  1.99977414,  2.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.47009869,  0.47011626, -0.47000742,  0.46991587,  0.4701753 ,\n",
       "         0.47019308,  0.46993465, -0.47000742,  0.47000742,  0.47000742,\n",
       "         0.47000742, -0.47004278,  0.47000742, -0.47012442, -0.46995738,\n",
       "         0.47008264,  0.47010093,  0.47019147,  0.47000742, -0.47003669,\n",
       "         0.47000742,  0.46996242,  0.47000539,  0.47006011, -0.47017673,\n",
       "        -0.47011496,  0.46983053, -0.47024919,  0.46995887, -0.46986971,\n",
       "         0.47001584,  0.47000742,  0.47004188,  0.47000742,  0.46988372,\n",
       "         0.47000742,  0.46993035,  0.47000742, -0.47007038,  0.47000742,\n",
       "         0.47003461, -0.47019112, -0.46997949,  0.47002927,  0.47000742,\n",
       "         0.47013176,  0.47012384, -0.4699736 ,  0.46986921,  0.47000742,\n",
       "        -0.47000742,  0.47000742,  0.47000742,  0.47000742, -0.46991137,\n",
       "         0.47006439, -0.47000742, -0.47000742,  0.47001278, -0.47002981,\n",
       "        -0.47000742, -0.47000742,  0.47000742,  0.46971382,  0.47000742,\n",
       "         0.46997097,  0.47000742,  0.47000742, -0.46992671,  0.47000742,\n",
       "         0.47000742, -0.47005411,  0.46989807,  0.47000742,  0.47000742,\n",
       "         0.47000742,  0.47000742,  0.47000742,  0.46990996,  0.46988252,\n",
       "         0.46983366,  0.46997521,  0.47000742, -0.47000742, -0.47000742,\n",
       "         0.47018867,  0.47000742,  0.47010783, -0.46999737,  0.47019382,\n",
       "         0.47002808,  0.47000742, -0.47019337, -0.47000742, -0.46999649,\n",
       "         0.47000742,  0.47005527, -0.47026428,  0.47000742,  0.47000742,\n",
       "         0.47000742,  0.46975326, -0.47003557,  0.47009755, -0.46994125,\n",
       "         0.47000742, -0.47000742, -0.47000742, -0.47007275, -0.47000742,\n",
       "        -0.470224  , -0.47006648,  0.4698639 ,  0.46997058,  0.46995066,\n",
       "         0.46980689,  0.47004598, -0.47000742,  0.47000742,  0.47001257,\n",
       "         0.47000742, -0.47000742,  0.47000742,  0.47000742, -0.47000742,\n",
       "         0.47000742, -0.470016  ,  0.47011195, -0.47031063, -0.47000742,\n",
       "         0.47000742,  0.46988629,  0.47000742, -0.46994135, -0.47000742,\n",
       "        -0.47000742, -0.4700593 , -0.47002978,  0.47002582,  0.47000742,\n",
       "         0.46991602,  0.47000742, -0.47011952,  0.47000742, -0.47001767,\n",
       "        -0.47000507, -0.46983571,  0.47000742, -0.47015108, -0.47000742,\n",
       "         0.46997519,  0.46992622,  0.46993724, -0.46992767,  0.46998527,\n",
       "         0.47002039, -0.47000742,  0.47000742,  0.47017515,  0.47000742,\n",
       "         0.46983742,  0.47020926, -0.46997832,  0.47000742, -0.46977068,\n",
       "         0.46998894, -0.47000742,  0.47000742,  0.47000742, -0.46979514,\n",
       "        -0.47000742, -0.47000742,  0.47000742,  0.47000742, -0.47000742,\n",
       "        -0.46986338,  0.47000742, -0.47000742,  0.46991961, -0.46995315,\n",
       "         0.4701604 ,  0.47000742,  0.47009861,  0.47000742,  0.47000742,\n",
       "        -0.47000742,  0.46994816,  0.46994959, -0.46993795,  0.47000742,\n",
       "         0.46999104,  0.47006875, -0.46979094,  0.47000742,  0.46994026,\n",
       "         0.47000742,  0.469908  , -0.47000742,  0.46968312,  0.46991288,\n",
       "        -0.46984551,  0.4700119 ,  0.47000742,  0.47003699,  0.46987843,\n",
       "         0.46981491,  0.47004411,  0.46996085,  0.47000742]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the Forward parameters for W, b and and activations for layer -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
