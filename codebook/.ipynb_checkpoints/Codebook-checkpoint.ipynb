{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch Lambda Function\n",
    "The `launch.py` Lambda Function is triggered by the S3 event where training data is uploaded to S3. It further initiliazes the various components needed, such as:\n",
    "1. State as well as the outputs of each epoch/iteration in DynamoDB:\n",
    "    - Training Set Accuracy.\n",
    "    - Test Set Accuracy.\n",
    "    - Weight paramter.\n",
    "    - Bias parameter.\n",
    "2. Temporary S3 Storage:\n",
    "    - The Output data of each layer and neauron over each epoch.\n",
    "    - This data is a series of `numpy` arrays that is leveraged as input data by the next layer or epoch/iteration.\n",
    "3. Preprocessing the Input Data: \n",
    "    - Read in the the initial *training*, *test* sets as well as the associated *class* of Cat images.\n",
    "    - The function initially loads the data in `h5py` format and extracts the *training*, *test* and *class* information.\n",
    "    - The function further performs any standardization and normalization of the input data.\n",
    "    - The function also \"*flattens*\" the data into a column vector, thus performing **Vectorization**.\n",
    "    - This data is dumped to the temporary S3 location and will thus serve as **Layer 0** of the Neural Network.\n",
    "4. Environment Variables:\n",
    "    - These setting are stored on the S3 along with the Input Data, in a `settings.json` file.\n",
    "    - The settings include overall parameters used by the `trainer` and `neuron` Lambda Functions, such as:\n",
    "        - Total number of epochs/iterations.\n",
    "        - Total number of layers in the Neural Network (including the Output layer).\n",
    "        - Total number of \"neurons\" in each layer.\n",
    "        - The activation function to be used for each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Libraries, Global and Event Variables\n",
    "\n",
    "The cell below imports all the packages that will be needed by the Lambda Function. \n",
    "- [numpy](www.numpy.org) is the fundamental package for scientific computing with Python.\n",
    "- [h5py](http://www.h5py.org) is a common package to interact with a dataset that is stored on an H5 file.\n",
    "- [matplotlib](http://matplotlib.org) is a famous library to plot graphs in Python.\n",
    "- [PIL](http://www.pythonware.com/products/pil/) and [scipy](https://www.scipy.org/) are used here to test your model with your own picture at the end.\n",
    "- [boto3](https://pypi.python.org/pypi/boto3) is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python, which allows Python developers to write software that makes use of services like Amazon S3 and Amazon EC2.\n",
    "- [json](https://docs.python.org/3/library/json.html) is a lightweight data interchange format inspired by JavaScript object literal syntax (although it is not a strict subset of JavaScript.\n",
    "- [os](https://docs.python.org/3/library/os.html) is a module the provides a portable way of using operating system dependent functionality. Particularly the  `environ` object is a nmapping object representing the environment.\n",
    "- [uuid](https://docs.python.org/2/library/uuid.html#uuid.uuid4) creates a unique, random ID.\n",
    "- The [io](https://docs.python.org/2/library/io.html) module provides the Python interfaces to stream handling.\n",
    "- The Python interface to the [Redis](https://pypi.python.org/pypi/redis) key-value store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries needed by the Lambda Function\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy\n",
    "import os\n",
    "from os import environ\n",
    "import json\n",
    "from json import dumps\n",
    "from boto3 import client, resource, Session\n",
    "import botocore\n",
    "import uuid\n",
    "import io\n",
    "from redis import StrictRedis as redis\n",
    "\n",
    "# Import libraries needed for the Codebook\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adiitionally, the S3 event trigger will supply the specifics of the Input Data being uploaded to a dedicated bucket and folder in S3. For the sake of testing, the event parameters are simulated in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simulate S3 event trigger data\n",
    "event = {\n",
    "    \"Records\": [\n",
    "        {\n",
    "            \"eventVersion\": \"2.0\",\n",
    "            \"eventTime\": \"1970-01-01T00:00:00.000Z\",\n",
    "            \"requestParameters\": {\n",
    "                \"sourceIPAddress\": \"127.0.0.1\"\n",
    "             },\n",
    "            \"s3\": {\n",
    "                \"configurationId\": \"testConfigRule\",\n",
    "                \"object\": {\n",
    "                    \"eTag\": \"0123456789abcdef0123456789abcdef\",\n",
    "                    \"sequencer\": \"0A1B2C3D4E5F678901\",\n",
    "                    \"key\": \"training_input/datasets.h5\",\n",
    "                    \"size\": 1024\n",
    "                },\n",
    "                \"bucket\": {\n",
    "                    \"arn\": \"arn:aws:s3:::lnn\",\n",
    "                    \"name\": \"lnn\",\n",
    "                    \"ownerIdentity\": {\n",
    "                        \"principalId\": \"EXAMPLE\"\n",
    "                    }\n",
    "                },\n",
    "                \"s3SchemaVersion\": \"1.0\"\n",
    "            },\n",
    "            \"responseElements\": {\n",
    "                \"x-amz-id-2\": \"EXAMPLE123/5678abcdefghijklambdaisawesome/mnopqrstuvwxyzABCDEFGH\",\n",
    "                \"x-amz-request-id\": \"EXAMPLE123456789\"\n",
    "            },\n",
    "            \"awsRegion\": \"us-west-2\",\n",
    "            \"eventName\": \"ObjectCreated:Put\",\n",
    "            \"userIdentity\": {\n",
    "                \"principalId\": \"EXAMPLE\"\n",
    "            },\n",
    "            \"eventSource\": \"aws:s3\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Simulate TrainerLambda ARN\n",
    "#environ[str('TrainerLambda')] = str(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** For this version of the implementation, the S3 Bucket is called **lnn** and the folder is called **training_input**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To establish client connectivity to the various AWS services that the function will leverage, the following cell creates the needed clients as global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "s3_client = client('s3', region_name='us-west-2') # S3 access\n",
    "s3_resource = resource('s3')\n",
    "redis_client = client('elasticache', region_name='us-west-2')\n",
    "lambda_client = client('lambda', region_name='us-west-2') # Lambda invocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Data Overview\n",
    "### 2.1 - Datasets\n",
    "It is **very important** in Neural Network programming (without the useof a Deep Learning Framework), to have a full understanding of the dimensions of the input data as well as how the dimensions are transformed at each layer, therefore to build a simple image-recognition algorithm that can correctly classify pictures as cat or non-cat, the following cells explain the datsets.\n",
    "\n",
    "To train the Neural Network, we are provided with a dataset (`datasets.h5`) contaning:\n",
    "- a training set of $m$ images containing cats and non-cats as well as the appropriate class labels ($y=1$) and non-cat images ($y=0$).\n",
    "- a test set of $m$ images containing cats and non-cat sas well as the appropriate class labels ($y=1$) and non-cat images ($y=0$).\n",
    "- classes list for cat and non-cat images.\n",
    "\n",
    ">**Note:** The original dataset was comprised of two seprate files, `test_catvnoncat.h5` and `train_catvnoncat.h5`. For the sake of this implementation a single file is needed to upload to the *S3 Bucket*, `datasets.h5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_classes\n",
      "test_set_x\n",
      "test_set_y\n",
      "train_set_x\n",
      "train_set_y\n"
     ]
    }
   ],
   "source": [
    "# Load main dataset\n",
    "dataset = h5py.File('datasets/datasets.h5', \"r\")\n",
    "\n",
    "# Get the names of the unique datsets\n",
    "datasetNames = [n for n in dataset.keys()]\n",
    "for n in datasetNames:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create numpy arrays of the various unique datasets\n",
    "train_set_x_orig = np.array(dataset[\"train_set_x\"][:]) # train set features\n",
    "train_set_y_orig = np.array(dataset[\"train_set_y\"][:]) # train set labels\n",
    "test_set_x_orig = np.array(dataset[\"test_set_x\"][:]) # test set features\n",
    "test_set_y_orig = np.array(dataset[\"test_set_y\"][:]) # test set labels\n",
    "classes = np.array(dataset[\"list_classes\"][:]) # the list of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x_orig dimensions: (209, 64, 64, 3)\n",
      "train_set_y_orig dimension: (209,)\n",
      "test_set_x_orig dimensions: (50, 64, 64, 3)\n",
      "test_set_y_orig dimensions: (50,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaye the dimensions of each unique data set\n",
    "print(\"train_set_x_orig dimensions: \" + str(train_set_x_orig.shape))\n",
    "print(\"train_set_y_orig dimension: \" + str(train_set_y_orig.shape))\n",
    "print(\"test_set_x_orig dimensions: \" + str(test_set_x_orig.shape))\n",
    "print(\"test_set_y_orig dimensions: \" + str(test_set_y_orig.shape))\n",
    "test_set_y_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the cell above, the image data (`train_set_x_orig` and `test_set_x_orig`) are 4-dimensional arrays consiting of $209$ training examoples (**m_train**) and $50$ testing images (**m_test**) respecitivaly. Each image is in turn of *height*, *width* and *depth* (**R**ed, **G**reen **B**lue values) of $64 \\times 64 \\times 3$.\n",
    "\n",
    "Additionally, the dimentsion for the labels (`train_set_y_orig` and `test_set_y_orig`) only show a $209$ and $50$ column structure. So it is recommended when coding new networks, don't use data structures where the shape is $5$, or $n$, rank 1 array. Instead, this is set to, `(1, 209)` and `(1, 50)`, to make them a **row vector**, and in essence add another dimension to the `Numpy` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create row vectors for the labels.\n",
    "train_set_y = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "test_set_y = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_y dimensions: (1, 209)\n",
      "test_set_y dimensions: (1, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"train_set_y dimensions: \" + str(train_set_y.shape))\n",
    "print(\"test_set_y dimensions: \" + str(test_set_y.shape))\n",
    "test_set_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Now that the additional dimension has been added to the label data, we can note the additional \"[[ ]]\" when displaying the array.\n",
    "\n",
    "Next we can see the label data and view the corresponding image, in this case, $index = 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = [1], and therefore it's a 'cat' picture.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niBM/ImIFESd+RMQKIk78iIgVxP8PtKLrLi0y5jMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe5b5fbc748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a cat picture\n",
    "index = 2\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "print (\"y = \" + str(train_set_y[:, index]) + \\\n",
    "       \", and therefore it's a '\" + \\\n",
    "       classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") + \\\n",
    "       \"' picture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.squeeze()` method extracts the \" inner dimension\" of the array, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_y[:, index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(train_set_y[:, index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    ">**Note:** The \"[ ]\" has been removed.\n",
    "\n",
    "\n",
    "### 2.2 - Data Preprocessing\n",
    "The final model is expecting a traing set and a test set represented by a numpy array of shape (no. pixels $\\times$ no. pixels $\\times$ depth, data set size) respectivley. In turn, the model is expecting the training set and test set labels represented as a numpy array (vector) of shape (1, data set size) respectivley.\n",
    "\n",
    ">**Note:** It is not determined as yet wether the \"vectorization\" of the images should be performed by the `TrainerLambda` to set up the inputs for *Layer 0*. For the sake of Version 1.0, the preprocessing of the input data will be performed by `launch.py` as various helper functions.\n",
    "\n",
    "#### 2.2.1 - Vectorize\n",
    "The images are represented by a 3D array of shape $(length, height, depth = 3)$. However, when an image is read as the input of an algorithm it is converted to a vector of shape $(length*height*3, 1)$. In other words, it is \"unrolled\", \"flattened\" or \"reshaped\" from a 3D array into a 1D vector as can be seen below.\n",
    "\n",
    "<img src=\"images/vectorization.png\" style=\"width:500px;height:300;\">\n",
    "\n",
    "The following cells show explais of this process using the `train_set_x_orig` numpy array. The end result for the input to the model is a is a numpy array where where each column represents a flattenned image in a matrix with all the inpute features (images) being a colum, $209$ for the training set and $50$ for the test set repsectivley."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (209, 64, 64, 3)\n",
      "Flattened shape: (209, 12288)\n",
      "Transpose: (12288, 209)\n"
     ]
    }
   ],
   "source": [
    "# Copy of origional training set\n",
    "orig = train_set_x_orig\n",
    "print(\"Original shape: \" + str(orig.shape))\n",
    "\n",
    "# \"vectorize\" or flatten out the array into an 1D vector\n",
    "flatten = orig.reshape(orig.shape[0], -1)\n",
    "print(\"Flattened shape: \"+ str(flatten.shape))\n",
    "\n",
    "# Transpose into a colums\n",
    "flatten_T = flatten.T\n",
    "print(\"Transpose: \" + str(flatten_T.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** For further intuation of what the above code is doing, the following shows a more \"manual\", alternate way.\n",
    "\n",
    "#### 2.2.2 - Standardize\n",
    "To represent color images, the red, green and blue channels (RGB) must be specified for each pixel, and so the pixel value is actually a vector of three numbers ranging from $0$ to $255$. One common preprocessing step in machine learning is to substract the mean of the whole numpy array from each example, and then divide each example by the standard deviation of the whole numpy array. But for picture datasets, it is simpler and more convenient and works almost as well to just divide every row of the dataset by $255$ (the maximum value of a pixel channel). \n",
    "\n",
    "\n",
    ">**Note:** During the training of the model, the weights willbe multiplied and biases added to the initial inputs in order to observe neuron activations. Then it will backpropogate with the gradients to train the model. But, it is extremely important for each feature to have a similar range such that our gradients don't explode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x shape: (12288, 209)\n",
      "sample value: 0.266666666667\n"
     ]
    }
   ],
   "source": [
    "# Load datsets for preprocessing after vectorization\n",
    "train_set_x = (train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T) / 255\n",
    "test_set_x = (test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T) / 255\n",
    "print(\"train_set_x shape: \" + str(train_set_x.shape))\n",
    "print(\"sample value: \" + str(train_set_x[index][index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Function Components\n",
    "### 3.1 Helper Functions\n",
    "#### `numpy2cache()`\n",
    "Seializes a Numpy array to a binary string and stores it in the Redis cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a 2D array to serialize\n",
    "A = train_set_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float64'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten the 2D NumPy array and save it as a binary string\n",
    "array_dtype = str(A.dtype)\n",
    "array_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12288\n",
      "209\n"
     ]
    }
   ],
   "source": [
    "l, w = A.shape\n",
    "print(l)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A.ravel().tostring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (AccessDenied) when calling the DescribeCacheClusters operation: User: arn:aws:sts::722812380636:assumed-role/ecs-task-lambda/af242cee-2b3a-48e1-80d7-099ec77ba0ba is not authorized to perform: elasticache:DescribeCacheClusters",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1e51e1ee0e14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get the ElastiCache endpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mredis_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe_cache_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CacheClusters'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ConfigurationEndpoint'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    311\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (AccessDenied) when calling the DescribeCacheClusters operation: User: arn:aws:sts::722812380636:assumed-role/ecs-task-lambda/af242cee-2b3a-48e1-80d7-099ec77ba0ba is not authorized to perform: elasticache:DescribeCacheClusters"
     ]
    }
   ],
   "source": [
    "# Get the ElastiCache endpoint\n",
    "cc = redis_client.describe_cache_clusters()\n",
    "for cluster in cc.get('CacheClusters'):\n",
    "  print(cluster.get('ConfigurationEndpoint'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a key as a UNIX timestamp w/ array shape appended to end of key delimited by '|'\n",
    "db = redis(db=0)\n",
    "key = '{0}|{1}#{2}#{3}'.format(int(time.time()), array_dtype, l, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store the binary string in redis\n",
    "db.set(key, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# retrieve the proto-array from redis\n",
    "A1 = db.get(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# deserialize it \n",
    "array_dtype, l, w = key.split('|')[1].split('#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = NP.fromstring(A1, dtype=array_dtype).reshape(int(l), int(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `name2str()`\n",
    "Converts the name of the numpy array to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def name2str(obj, namespace):\n",
    "    \"\"\"\n",
    "    Converts the name of the numpy array to string\n",
    "    \n",
    "    Arguments:\n",
    "    obj -- Numpy array object\n",
    "    namespace -- dictionary of the current global symbol table\n",
    "    \n",
    "    Return:\n",
    "    List of the names of the Numpy arrays\n",
    "    \"\"\"\n",
    "    return [name for name in namespace if namespace[name] is obj]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `vectorize()`\n",
    "Reshapes (flatten) the image data to column vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(x_orig):\n",
    "    \"\"\"\n",
    "    Vectorize the image data into a matrix of column vectors\n",
    "    \n",
    "    Argument:\n",
    "    x_orig -- Numpy array of image data\n",
    "    \n",
    "    Return:\n",
    "    Reshaped/Transposed Numpy array\n",
    "    \"\"\"\n",
    "    return x_orig.reshape(x_orig.shape[0], -1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `standardize()`\n",
    "Preprocess the image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize(x_orig):\n",
    "    \"\"\"\n",
    "    Standardize the input data\n",
    "    \n",
    "    Argument:\n",
    "    x_orig -- Numpy array of image data\n",
    "    \n",
    "    Return:\n",
    "    Call to `vectorize()`, stndrdized Numpy array of image data\n",
    "    \"\"\"\n",
    "    return vectorize(x_orig) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `initialize_data()`\n",
    ">**Note:** For the sake of testing, the following is not defined as function.\n",
    "\n",
    "Extracts the training and testing data from S3, flattens, standardizes, initializes the weights and bias and then creates an entry in Elastiache for neurons to process as layer $a^{[0]}$.\n",
    "\n",
    "Returns:  \n",
    "a_name -- list of the Numpy array names  \n",
    "dims --- dimensions of each of the data sets  \n",
    "params -- dictionary of the weight and bias parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fake parametyers for w and b since this is not a function\n",
    "#w = 0\n",
    "#b = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load main dataset\n",
    "dataset = h5py.File('/tmp/datasets.h5', \"r\")\n",
    "\n",
    "# Create numpy arrays from the various h5 datasets\n",
    "train_set_x_orig = np.array(dataset[\"train_set_x\"][:]) # train set features\n",
    "train_set_y_orig = np.array(dataset[\"train_set_y\"][:]) # train set labels\n",
    "test_set_x_orig = np.array(dataset[\"test_set_x\"][:]) # test set features\n",
    "test_set_y_orig = np.array(dataset[\"test_set_y\"][:]) # test set labels\n",
    "classes = np.array(dataset[\"list_classes\"][:]) # the list of classes\n",
    "\n",
    "# Reshape labels\n",
    "train_set_y = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "test_set_y = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "# Preprocess inputs\n",
    "train_set_x = standardize(train_set_x_orig)\n",
    "test_set_x = standardize(test_set_x_orig)\n",
    "\n",
    "# Dump the inputs to the temporary s3 bucket for TrainerLambda\n",
    "#bucket = storage_init() # Creates a temporary bucket for the propogation steps\n",
    "dims = {} # data dimensions\n",
    "a_list = [train_set_x, train_set_y, test_set_x, test_set_y, classes]\n",
    "a_names = []\n",
    "for i in range(len(a_list)):\n",
    "    # Create a lis of the names of the numpy arrays\n",
    "    a_names.append(name2str(a_list[i], globals()))\n",
    "for j in range(len(a_list)):\n",
    "    # \n",
    "    numpy2s3(array=a_list[j], name=a_names[j][0])\n",
    "    dims[str(a_names[j][0])] = a_list[j].shape\n",
    "    \n",
    "# Initialize weights and bias data\n",
    "if w == 0: # Initialize weights to dimensions of the input data\n",
    "    dim = dims.get('train_set_x')[0]\n",
    "    weights = np.zeros((dim, 1))\n",
    "    # Store the initial weights as a column vector on S3\n",
    "    numpy2s3(weights, name='weights')\n",
    "else:\n",
    "    #placeholder for random weight initialization\n",
    "    pass\n",
    "        \n",
    "# Initialize Bias\n",
    "if b != 0:\n",
    "    #placeholder for random bias initialization\n",
    "    pass\n",
    "else:\n",
    "    numpy2s3(b, name='bias')\n",
    "    \n",
    "# Create the initial paramaters for `TrainerLambda`\n",
    "params = {\n",
    "    'w': w,\n",
    "    'b': b\n",
    "}   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a **Sanity Check** to verify that the Numpy arrays in memory correspond to the Numpy Arrays copied to S3.\n",
    ">**Side Note:** It might be a good practice to insert assertion statements here as part of debuggin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "s32numpy = io.BytesIO(s3_client.get_object(Bucket=bucket, Key='train_set_x')['Body'].read())\n",
    "content = s32numpy.getvalue()\n",
    "data = np.load(io.BytesIO(content))\n",
    "print(\"train_set_x shape: \" + str(train_set_x.shape))\n",
    "print(\"sample value from training data: \" + str(train_set_x[index][index]))\n",
    "print(\"data shape: \" + str(data.shape))\n",
    "print(\"sample value from s3 data: \" + str(data[index][index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Function returns the name of the S3 temporary Bucket as well as list containing the names of the numpy arrays in S3 as the input data files. Thes variables are added to the `payload` for the `TrainerLambda`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Lambda Handler\n",
    "#### Process `event` variables\n",
    "Within the `event` variables are the specifics of the S3 environment from which the Lambda Function is triggered. The first objective is to capture the S3 *Bucket* and S3 *Key* in order to get the Network Architecture setting and the input data that traiggered the event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrieve datasets and setting from S3\n",
    "input_bucket = s3_resource.Bucket(str(event['Records'][0]['s3']['bucket']['name']))\n",
    "dataset_key = str(event['Records'][0]['s3']['object']['key'])\n",
    "settings_key = dataset_key.split('/')[-2] + '/parameters.json'\n",
    "try:\n",
    "    input_bucket.download_file(dataset_key, '/tmp/datasets.h5')\n",
    "    input_bucket.download_file(settings_key, '/tmp/parameters.json')\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == '404':\n",
    "        print(\"Error downloading input data from S3, S3 object does not exist\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Neural Network Settings\n",
    "the various settings from `settings.json` are appended to the environment settings to be used later as the pyaload for the *Trainer* Lambda Function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the neural network parameters\n",
    "with open('/tmp/parameters.json') as parameters_file:\n",
    "    parameters = json.load(parameters_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process the `payload` to send to the *Trainer* Lambda Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create payload parameters from neural network parameters\n",
    "payload = {}\n",
    "payload['epochs'] = parameters['epochs']\n",
    "payload['layers'] = parameters['layers']\n",
    "payload['activations'] = parameters['activations']\n",
    "payload['neurons'] = parameters['neurons']\n",
    "payload['learning_rate'] = parameters['learning_rate']\n",
    "\n",
    "# Create payload parameters showing \"current state\" for TrainerLambda\n",
    "# Next epoch to process\n",
    "payload['epoch'] = 1\n",
    "\n",
    "# Next Layer to process\n",
    "payload['layer'] = 0\n",
    "\n",
    "# Variable to initialize the weights and bias to\n",
    "#payload['w'] = parameters['weight']\n",
    "#payload['b'] = parameters['bias']\n",
    "payload['params'] = params\n",
    "\n",
    "# Input data sets\n",
    "#payload['s3_bucket'], payload['input_data'] = initialize_data() # Returns S3 Bucket of input data to process\n",
    "# Simulate return variables from initialize_data()\n",
    "payload['s3_bucket'] = bucket\n",
    "payload['input_data'] = [j for i in a_names for j in i]\n",
    "\n",
    "# State tracking table\n",
    "#payload['state_table'] = dynamo_init('state)\n",
    "# Simulate return variables from dynamo_init()\n",
    "payload['state_table'] = table.name\n",
    "\n",
    "# Since dimensions of the data is very important, \n",
    "# supply the training set and test set dimensions\n",
    "payload['dimensions'] = dims\n",
    "payload['state'] = 'start'\n",
    "payloadbytes = dumps(payload)\n",
    "\n",
    "# Show final payload going to the `trainerLambda` Function\n",
    "payloadbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Side Note**: An alternate method to *List Comprehension* is to use the `chain()` function to get the names of the Numpy arrays, as the following code cell shows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "list(chain.from_iterable(a_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test using dynamodb to store setting instead of event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new item in DynamoDB for setting\n",
    "table = dynamo_init('settings', 'settings', 'S')\n",
    "table.put_item(\n",
    "    Item={\n",
    "        'setting': 'Neural Network',\n",
    "        'epochs': parameters['epochs'],\n",
    "        'layers': parameters['layers'],\n",
    "        'activations': parameters['activations'],\n",
    "        'neurons': parameters['neurons'],\n",
    "        'learning_rate': Decimal(parameters['learning_rate']),\n",
    "        's3_bucket': bucket,\n",
    "        'input_data': [j for i in a_names for j in i],\n",
    "        'params': params\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investogate usings a settings file with all the parameters on S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Launch the `TrainerLambda` Function\n",
    "\n",
    "```python\n",
    "# kick off lambda for next layer\n",
    "    response = lambda_client.invoke(\n",
    "        FunctionName=environ['TrainerLambda'], #ENSURE ARN POPULATED BY CFN OR S3 EVENT\n",
    "        InvocationType='Event',\n",
    "        Payload=payloadbytes\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Trainer Lambda Function\n",
    "The `trainer.py` Lambda Function is the most critical funciton in the set in that it:\n",
    "1. Tracks and updates the state across the interations/epochs and the various layers of the Neural Network.\n",
    "2. Launches the various Neurons (`NeuraonLamabda`) in ech layer and tracks their output.\n",
    "\n",
    "In order to accomplish this, the `TrainerLambda` has three possible states, `start`, `forward` and `backward`:\n",
    "1. `start`: This state starts the initial or subsequent training epochs and performs the following:\n",
    "    - Initializes the new weights and bias for the epoch.\n",
    "    - Updates the state table with these values.\n",
    "2. `forward`: This state processes the *forward* porpogation step and launches the various hidden layer/s Neurons and supplies the necessary state information to these functions, such as:\n",
    "    - Input data location\n",
    "    - Wights and Bias.\n",
    "    - Hidden Layer No.\n",
    "    - Number of Hidden Units.\n",
    "    - Activation Funciton for the Layer.\n",
    "3. `backward`: This state processes the *back* propogation/optimization step and launches the various hidden layer/s Neurons as well as supplies the necessary information for these functions, like:\n",
    "    - Gradient Parameters\n",
    "    - Hidden Layer No.\n",
    "    - Number of Hidden Units.\n",
    "    - Learning Rate.\n",
    "    - Loss function calculated fromthe Forward propogation step.\n",
    "\n",
    ">**Side Note**: Ther may be a necessity later on when dealing with multiple hidden layers, to combine the `forward` and `backward` states into a `propogate` state and then have a separate `optimize` state for **Gradient Decent**.\n",
    "\n",
    "## 1 - Libraries, Global and Event Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries needed by the Lambda Function\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy\n",
    "import os\n",
    "from os import environ\n",
    "import json\n",
    "from json import dumps\n",
    "from boto3 import client, resource, Session\n",
    "import botocore\n",
    "import uuid\n",
    "import io\n",
    "from decimal import Decimal, Inexact, Rounded\n",
    "from boto3.dynamodb.types import DYNAMODB_CONTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "s3_client = client('s3', region_name='us-west-2') # S3 access\n",
    "s3_resource = resource('s3')\n",
    "dynamo_client = client('dynamodb', region_name='us-west-2') # DynamoDB access\n",
    "dynamodb = resource('dynamodb', region_name='us-west-2')\n",
    "DYNAMODB_CONTEXT.traps[Inexact] = 0\n",
    "DYNAMODB_CONTEXT.traps[Rounded] = 0\n",
    "lambda_client = client('lambda', region_name='us-west-2') # Lambda invocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Function Components\n",
    "### 2.1 Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `numpy2s3(array, name, bucket)`\n",
    "Write a numpy array to S3 as a file, without using local copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numpy2s3(array, name, bucket):\n",
    "    \"\"\"\n",
    "    Write a numpy array to S3 as a file, without using local copy\n",
    "    \n",
    "    Arguments:\n",
    "    array -- Numpy array to save to s3\n",
    "    name -- file of the saved Numpy array\n",
    "    \"\"\"\n",
    "    f_out = io.BytesIO()\n",
    "    np.save(f_out, array)\n",
    "    try:\n",
    "        s3_client.put_object(Key=name, Bucket=bucket, Body=f_out.getvalue(), ACL='bucket-owner-full-control')\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `finish()`\n",
    "\n",
    "#### `propogate()`\n",
    "\n",
    "#### `optimize()` -> May not be necessary!!!\n",
    "\n",
    "#### `loss()`\n",
    "\n",
    "#### `update_state()`\n",
    "\n",
    "### 2.2 Lambda Handler\n",
    "#### Process `event` variables\n",
    "Within the `event` variables are the specifics of the state, either passed from the `LaunchLambda` function or `NeuronLambda` Function and detail the \"next strep\". To provide an overview of this, the following code will execute based on data passed from the `LaunchLambda` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simulate event varibales from `TrainerLambda`\n",
    "event = payload\n",
    "event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Execute appropriate action based on the the current state\n",
    "# Get the current state\n",
    "current_state = event.get('state')\n",
    "if current_state == 'forward':\n",
    "    # Get important state variables\n",
    "    \n",
    "    # Determine the location within forwardprop\n",
    "    if layer > layers:\n",
    "        # Location is at the end of forwardprop\n",
    "        # Caculate the Loss function\n",
    "        \n",
    "        # Update the Loss function to Dynamo\n",
    "        \n",
    "        # Start backprop\n",
    "        #propogate(direction='backward', layer=layer-1)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        # Move to the next hidden layer\n",
    "        #propogate(direction='forward', layer=layer+1, activations=activations)\n",
    "        \n",
    "        pass\n",
    "\n",
    "elif current_state == 'backward':\n",
    "    # Get important state variables\n",
    "    \n",
    "    # Determine the location within backprop\n",
    "    if epoch == epochs and layer == 0:\n",
    "        # Location is at the end of the final epoch\n",
    "        \n",
    "        # Caculate derivative?????????????????????????\n",
    "        \n",
    "        # Caclulate the absolute final weight\n",
    "        \n",
    "        # Update the final weights and results (cost) to DynamoDB\n",
    "        \n",
    "        # Finalize the the process and clean up\n",
    "        #finish()\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    elif epoch < epochs and layer == 0:\n",
    "        # Location is at the end of the current epoch and backprop is finished\n",
    "        # Calculate the derivative?????????????????????????\n",
    "        \n",
    "        # Calculate the weights for this epoch\n",
    "        \n",
    "        # Update the weights and results (cost) to DynamoDB\n",
    "        \n",
    "        # Start the next epoch\n",
    "        #epoch = epoch + 1\n",
    "        #start(epoch)\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    else:\n",
    "        # Move to the next hidden layer\n",
    "        #propogate(direction='backward', layer=layer-1)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "elif current_state == 'start':\n",
    "    # Start of a new run of the process\n",
    "    # Get important event variables from event triggerd from `LaunchLambda`\n",
    "    s3_bucket = event['s3_bucket']\n",
    "    state_table = event['state_table']\n",
    "    learning_rate = event['learning_rate']\n",
    "    #weights = event['w']\n",
    "    #bias = event['b']\n",
    "    epochs = event['epochs']\n",
    "    epoch = event['epoch']\n",
    "    layers = event['layers']\n",
    "    layer = event['layer']\n",
    "    activations = event['activations']\n",
    "    #neurons = event.get('neurons')['layer' + str(layer)]\n",
    "    #current_activation = event.get('activations')['layer' + str(current_layer)]\n",
    "    \n",
    "    # Initialize Weights\n",
    "    #if weights == 0: # Initial weights to dimensions of input data\n",
    "    #    dims = event.get('dimensions')['train_set_x'][0]\n",
    "    #    w = np.zeros((dims, 1))\n",
    "    #    # Store the initial Weights data to S3 for Neurons\n",
    "    #    numpy2s3(w, name='weights', bucket=s3_bucket)\n",
    "        \n",
    "    #else:\n",
    "    #    #placeholder for random initialization of weights\n",
    "    #    pass\n",
    "    \n",
    "    # Initialize Bias\n",
    "    #if bias != 0:\n",
    "    #    #placeholder for other bias initialization\n",
    "    #    pass\n",
    "    #else:\n",
    "    #    b = bias\n",
    "    #    # Store the initial Bias data to S3 for Neurons\n",
    "    #    numpy2s3(b, name='bias', bucket=s3_bucket)\n",
    "    \n",
    "    # Create a epoch 1 in DynamoDB with ALL initial parameters\n",
    "    table = dynamodb.Table('state')\n",
    "    table.put_item(\n",
    "        Item = {\n",
    "            'epoch': epoch,\n",
    "            'epochs': epochs,\n",
    "            'layer': layer+1,\n",
    "            'learning_rate': Decimal(learning_rate),\n",
    "            'activations': activations,\n",
    "            'state_table': state_table,\n",
    "            's3_bucket': s3_bucket,\n",
    "            'params': event['params']\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Start forwardprop\n",
    "    #layer = layer + 1 # Shuould equate to 0+1\n",
    "    #propogate(direction='forward', layer=layer+1, activations=activations)\n",
    "\n",
    "else:\n",
    "    print(\"No state informaiton has been provided.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Side Note**: At the point of writing the codebook, the easiest way for the Neurons to process the input data as well as the weights (since it's a vector the same size as the input data *AND* an `ndarray`) is to store the weights with the input data. However as the networks become more complex, it would be a good practice to store the weights as part of the state in DynamoDB or an alternate Key,Value store similar to what `mxnet` uses. (See **Notes.md**)  \n",
    "\n",
    "**Sanity Check to confirm Weights from S3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s32numpy = io.BytesIO(s3_client.get_object(Bucket=bucket, Key='weights')['Body'].read())\n",
    "content = s32numpy.getvalue()\n",
    "data = np.load(io.BytesIO(content))\n",
    "print(\"Shape of train_set_x: \" + str(train_set_x.shape))\n",
    "print(\"Shape of w: \" + str(w.shape))\n",
    "print(\"Shape of data from s3: \" + str(data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note**: When getting the Bias data from S3, the result is a numpy array -> `array(0)`. Therefore is may be necessary when using the data in the `NeuronLambda`, to convert it to an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Appendix A: Build the Lambda Deployment Package"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "XaIWT",
   "launcher_item_id": "zAgPl"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
